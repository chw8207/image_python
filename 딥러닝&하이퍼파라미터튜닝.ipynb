{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15AjojxaU3wZMtDsVMfx-9u6BosSfN4J0",
      "authorship_tag": "ABX9TyPsbC4ctnAf4LzXS+pNcqFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chw8207/image_python/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%26%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%ED%8A%9C%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "66RbpN9_4X3w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import make_blobs\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers, optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 설정"
      ],
      "metadata": {
        "id": "Luo-1xmJ48KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0' :\n",
        "    raise SystemError('GPU device not found')\n",
        "print(f'Found GPU at: {device_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhjlNu8W4nmq",
        "outputId": "e21df18a-27d1-41f2-adfe-ae72ab4a0047"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12SPC2uO4ouv",
        "outputId": "7ce15904-9d29-46b9-cc0b-0549507c7b09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11796215995663506026\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14626652160\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 2989729227142906674\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 신경망의 구성, 학습, 평가 실습"
      ],
      "metadata": {
        "id": "iychPnCoIp8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 생성하기\n",
        "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)"
      ],
      "metadata": {
        "id": "kRTmknXW_eof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR1vX86IKC9Q",
        "outputId": "a0f76c70-40d5-4f7b-8388-f74fbd1a5b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 0, 1, 0, 1, 1, 2, 2, 1, 0, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0,\n",
              "       0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 0, 2, 1, 1, 2,\n",
              "       1, 0, 0, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 1, 1, 2, 0, 2, 0, 0, 1,\n",
              "       0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 0, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2,\n",
              "       1, 1, 2, 0, 2, 0, 0, 2, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 0, 0, 2,\n",
              "       0, 2, 1, 2, 0, 0, 0, 0, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 2, 0, 2, 0,\n",
              "       0, 0, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2,\n",
              "       1, 2, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 2, 1,\n",
              "       1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 0, 1,\n",
              "       1, 2, 2, 0, 2, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 0, 1, 2, 0, 1,\n",
              "       2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2,\n",
              "       2, 0, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0,\n",
              "       1, 0, 2, 2, 2, 1, 2, 0, 1, 1, 1, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 1,\n",
              "       0, 0, 2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 2, 0, 0, 0,\n",
              "       2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 2, 2, 0, 2, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 0, 1,\n",
              "       0, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 0, 2,\n",
              "       2, 0, 1, 1, 2, 0, 0, 0, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 0,\n",
              "       2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2, 1, 2,\n",
              "       1, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2,\n",
              "       0, 0, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       2, 1, 2, 1, 0, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 1, 1, 2,\n",
              "       1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 1,\n",
              "       1, 2, 0, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 1, 2, 2, 1, 1, 2, 2,\n",
              "       1, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 1, 2, 1, 1, 1,\n",
              "       2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 2, 0, 0, 2,\n",
              "       0, 1, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0, 2, 0, 1, 0, 0, 1, 2, 0,\n",
              "       2, 1, 2, 0, 1, 0, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2, 1, 0, 2, 1, 1, 2,\n",
              "       0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 2, 2, 1, 1,\n",
              "       1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1,\n",
              "       2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2,\n",
              "       0, 2, 1, 0, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 2, 1, 0, 0, 2,\n",
              "       2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2,\n",
              "       1, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 2, 1, 2,\n",
              "       0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2,\n",
              "       0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 0,\n",
              "       1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0, 0, 1,\n",
              "       2, 1, 0, 1, 1, 2, 1, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 1, 1, 2, 2, 1,\n",
              "       0, 0, 1, 2, 0, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 0, 0,\n",
              "       0, 2, 2, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0,\n",
              "       0, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 2, 2, 1, 0, 0, 1,\n",
              "       0, 2, 2, 0, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 2, 0, 1, 0,\n",
              "       2, 1, 1, 1, 0, 1, 0, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블에 원-핫 인코딩 적용\n",
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "a65S5KrOJL2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_bx8w2tKEuN",
        "outputId": "1a64ab2d-1b7b-4f98-8caf-a2b992edff2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 분류\n",
        "n_train = 800\n",
        "train_X, test_X = X[:n_train, :], X[n_train:, :]\n",
        "train_y, test_y = y[:n_train], y[n_train:]\n",
        "print(train_X.shape, test_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNirxSneJXXV",
        "outputId": "860b2e2f-e8ee-4dd3-a710-823c8515b4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 2) (200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=2, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P67B0o_L6K3",
        "outputId": "6477b750-379b-4af8-809d-b0559552e55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 25)                75        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 78        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153 (612.00 Byte)\n",
            "Trainable params: 153 (612.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_X, train_y, validation_data = (test_X, test_y), epochs=1000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQjuEdLqMUAJ",
        "outputId": "3e164bdf-b5f8-406b-cb95-957756563c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "25/25 [==============================] - 2s 13ms/step - loss: 0.9251 - accuracy: 0.4663 - val_loss: 0.8094 - val_accuracy: 0.5250\n",
            "Epoch 2/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.5462 - val_loss: 0.7254 - val_accuracy: 0.6250\n",
            "Epoch 3/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.7542 - accuracy: 0.6050 - val_loss: 0.6704 - val_accuracy: 0.7000\n",
            "Epoch 4/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.6513 - val_loss: 0.6367 - val_accuracy: 0.7350\n",
            "Epoch 5/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.6662 - val_loss: 0.6116 - val_accuracy: 0.7500\n",
            "Epoch 6/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.6800 - val_loss: 0.5899 - val_accuracy: 0.7500\n",
            "Epoch 7/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6938 - val_loss: 0.5744 - val_accuracy: 0.7650\n",
            "Epoch 8/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6316 - accuracy: 0.7025 - val_loss: 0.5610 - val_accuracy: 0.7800\n",
            "Epoch 9/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6190 - accuracy: 0.7075 - val_loss: 0.5468 - val_accuracy: 0.7850\n",
            "Epoch 10/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6085 - accuracy: 0.7237 - val_loss: 0.5360 - val_accuracy: 0.8050\n",
            "Epoch 11/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5985 - accuracy: 0.7212 - val_loss: 0.5283 - val_accuracy: 0.8350\n",
            "Epoch 12/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.7312 - val_loss: 0.5190 - val_accuracy: 0.8450\n",
            "Epoch 13/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.7337 - val_loss: 0.5072 - val_accuracy: 0.8350\n",
            "Epoch 14/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.5698 - accuracy: 0.7462 - val_loss: 0.5002 - val_accuracy: 0.8600\n",
            "Epoch 15/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.7600 - val_loss: 0.4899 - val_accuracy: 0.8500\n",
            "Epoch 16/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.7525 - val_loss: 0.4873 - val_accuracy: 0.8400\n",
            "Epoch 17/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.7713 - val_loss: 0.4779 - val_accuracy: 0.8400\n",
            "Epoch 18/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7763 - val_loss: 0.4681 - val_accuracy: 0.8400\n",
            "Epoch 19/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7763 - val_loss: 0.4676 - val_accuracy: 0.8400\n",
            "Epoch 20/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7837 - val_loss: 0.4533 - val_accuracy: 0.8450\n",
            "Epoch 21/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.5188 - accuracy: 0.7850 - val_loss: 0.4545 - val_accuracy: 0.8600\n",
            "Epoch 22/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7900 - val_loss: 0.4453 - val_accuracy: 0.8550\n",
            "Epoch 23/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7925 - val_loss: 0.4420 - val_accuracy: 0.8350\n",
            "Epoch 24/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.8500\n",
            "Epoch 25/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7937 - val_loss: 0.4285 - val_accuracy: 0.8450\n",
            "Epoch 26/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7987 - val_loss: 0.4293 - val_accuracy: 0.8450\n",
            "Epoch 27/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.8000 - val_loss: 0.4225 - val_accuracy: 0.8450\n",
            "Epoch 28/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.8037 - val_loss: 0.4139 - val_accuracy: 0.8550\n",
            "Epoch 29/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.8025 - val_loss: 0.4167 - val_accuracy: 0.8450\n",
            "Epoch 30/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.8062 - val_loss: 0.4109 - val_accuracy: 0.8500\n",
            "Epoch 31/1000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.8087 - val_loss: 0.4075 - val_accuracy: 0.8450\n",
            "Epoch 32/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.4667 - accuracy: 0.8075 - val_loss: 0.4044 - val_accuracy: 0.8500\n",
            "Epoch 33/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4643 - accuracy: 0.8037 - val_loss: 0.4041 - val_accuracy: 0.8450\n",
            "Epoch 34/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8087 - val_loss: 0.4000 - val_accuracy: 0.8450\n",
            "Epoch 35/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4581 - accuracy: 0.8075 - val_loss: 0.3986 - val_accuracy: 0.8600\n",
            "Epoch 36/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4554 - accuracy: 0.8050 - val_loss: 0.3935 - val_accuracy: 0.8550\n",
            "Epoch 37/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4521 - accuracy: 0.8050 - val_loss: 0.3998 - val_accuracy: 0.8550\n",
            "Epoch 38/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.8075 - val_loss: 0.3898 - val_accuracy: 0.8550\n",
            "Epoch 39/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.8138 - val_loss: 0.3911 - val_accuracy: 0.8550\n",
            "Epoch 40/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.4441 - accuracy: 0.8138 - val_loss: 0.3866 - val_accuracy: 0.8550\n",
            "Epoch 41/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.4417 - accuracy: 0.8100 - val_loss: 0.3886 - val_accuracy: 0.8550\n",
            "Epoch 42/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.8163 - val_loss: 0.3844 - val_accuracy: 0.8550\n",
            "Epoch 43/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8163 - val_loss: 0.3839 - val_accuracy: 0.8500\n",
            "Epoch 44/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8087 - val_loss: 0.3794 - val_accuracy: 0.8550\n",
            "Epoch 45/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.3801 - val_accuracy: 0.8500\n",
            "Epoch 46/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8125 - val_loss: 0.3861 - val_accuracy: 0.8350\n",
            "Epoch 47/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8175 - val_loss: 0.3803 - val_accuracy: 0.8550\n",
            "Epoch 48/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8150 - val_loss: 0.3759 - val_accuracy: 0.8550\n",
            "Epoch 49/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8175 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
            "Epoch 50/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8188 - val_loss: 0.3787 - val_accuracy: 0.8500\n",
            "Epoch 51/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8112 - val_loss: 0.3765 - val_accuracy: 0.8500\n",
            "Epoch 52/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8263 - val_loss: 0.3710 - val_accuracy: 0.8600\n",
            "Epoch 53/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8175 - val_loss: 0.3761 - val_accuracy: 0.8450\n",
            "Epoch 54/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8225 - val_loss: 0.3766 - val_accuracy: 0.8400\n",
            "Epoch 55/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8275 - val_loss: 0.3729 - val_accuracy: 0.8500\n",
            "Epoch 56/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8150 - val_loss: 0.3695 - val_accuracy: 0.8550\n",
            "Epoch 57/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8263 - val_loss: 0.3700 - val_accuracy: 0.8500\n",
            "Epoch 58/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8213 - val_loss: 0.3749 - val_accuracy: 0.8400\n",
            "Epoch 59/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8288 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
            "Epoch 60/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8263 - val_loss: 0.3712 - val_accuracy: 0.8450\n",
            "Epoch 61/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8275 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 62/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8238 - val_loss: 0.3711 - val_accuracy: 0.8400\n",
            "Epoch 63/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8238 - val_loss: 0.3671 - val_accuracy: 0.8500\n",
            "Epoch 64/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8275 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 65/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8288 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 66/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8238 - val_loss: 0.3650 - val_accuracy: 0.8550\n",
            "Epoch 67/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8300 - val_loss: 0.3653 - val_accuracy: 0.8500\n",
            "Epoch 68/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8250 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 69/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8288 - val_loss: 0.3691 - val_accuracy: 0.8450\n",
            "Epoch 70/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8300 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 71/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8250 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 72/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8250 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 73/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8288 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 74/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8288 - val_loss: 0.3692 - val_accuracy: 0.8400\n",
            "Epoch 75/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8313 - val_loss: 0.3637 - val_accuracy: 0.8450\n",
            "Epoch 76/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8288 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 77/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8275 - val_loss: 0.3673 - val_accuracy: 0.8400\n",
            "Epoch 78/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8313 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 79/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8300 - val_loss: 0.3718 - val_accuracy: 0.8450\n",
            "Epoch 80/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8288 - val_loss: 0.3677 - val_accuracy: 0.8400\n",
            "Epoch 81/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8275 - val_loss: 0.3680 - val_accuracy: 0.8400\n",
            "Epoch 82/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8313 - val_loss: 0.3625 - val_accuracy: 0.8450\n",
            "Epoch 83/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8288 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
            "Epoch 84/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8263 - val_loss: 0.3684 - val_accuracy: 0.8450\n",
            "Epoch 85/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8313 - val_loss: 0.3704 - val_accuracy: 0.8400\n",
            "Epoch 86/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8300 - val_loss: 0.3659 - val_accuracy: 0.8450\n",
            "Epoch 87/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8300 - val_loss: 0.3645 - val_accuracy: 0.8450\n",
            "Epoch 88/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8300 - val_loss: 0.3668 - val_accuracy: 0.8350\n",
            "Epoch 89/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8338 - val_loss: 0.3649 - val_accuracy: 0.8400\n",
            "Epoch 90/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8275 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 91/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8288 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 92/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8313 - val_loss: 0.3658 - val_accuracy: 0.8400\n",
            "Epoch 93/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8288 - val_loss: 0.3641 - val_accuracy: 0.8400\n",
            "Epoch 94/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8313 - val_loss: 0.3603 - val_accuracy: 0.8450\n",
            "Epoch 95/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8263 - val_loss: 0.3658 - val_accuracy: 0.8400\n",
            "Epoch 96/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8300 - val_loss: 0.3662 - val_accuracy: 0.8350\n",
            "Epoch 97/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8275 - val_loss: 0.3669 - val_accuracy: 0.8450\n",
            "Epoch 98/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8300 - val_loss: 0.3623 - val_accuracy: 0.8350\n",
            "Epoch 99/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8288 - val_loss: 0.3671 - val_accuracy: 0.8350\n",
            "Epoch 100/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8338 - val_loss: 0.3686 - val_accuracy: 0.8350\n",
            "Epoch 101/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8288 - val_loss: 0.3605 - val_accuracy: 0.8350\n",
            "Epoch 102/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8263 - val_loss: 0.3670 - val_accuracy: 0.8350\n",
            "Epoch 103/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8263 - val_loss: 0.3675 - val_accuracy: 0.8350\n",
            "Epoch 104/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8313 - val_loss: 0.3637 - val_accuracy: 0.8450\n",
            "Epoch 105/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8263 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 106/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8288 - val_loss: 0.3635 - val_accuracy: 0.8350\n",
            "Epoch 107/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8313 - val_loss: 0.3621 - val_accuracy: 0.8350\n",
            "Epoch 108/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.8300 - val_loss: 0.3713 - val_accuracy: 0.8450\n",
            "Epoch 109/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4063 - accuracy: 0.8288 - val_loss: 0.3565 - val_accuracy: 0.8450\n",
            "Epoch 110/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8275 - val_loss: 0.3720 - val_accuracy: 0.8400\n",
            "Epoch 111/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8325 - val_loss: 0.3626 - val_accuracy: 0.8350\n",
            "Epoch 112/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8250 - val_loss: 0.3627 - val_accuracy: 0.8350\n",
            "Epoch 113/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8325 - val_loss: 0.3642 - val_accuracy: 0.8350\n",
            "Epoch 114/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8313 - val_loss: 0.3626 - val_accuracy: 0.8350\n",
            "Epoch 115/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8325 - val_loss: 0.3609 - val_accuracy: 0.8350\n",
            "Epoch 116/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8313 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 117/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8325 - val_loss: 0.3635 - val_accuracy: 0.8350\n",
            "Epoch 118/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8300 - val_loss: 0.3603 - val_accuracy: 0.8350\n",
            "Epoch 119/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8300 - val_loss: 0.3642 - val_accuracy: 0.8400\n",
            "Epoch 120/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8300 - val_loss: 0.3659 - val_accuracy: 0.8350\n",
            "Epoch 121/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8325 - val_loss: 0.3659 - val_accuracy: 0.8350\n",
            "Epoch 122/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8288 - val_loss: 0.3633 - val_accuracy: 0.8350\n",
            "Epoch 123/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8275 - val_loss: 0.3697 - val_accuracy: 0.8450\n",
            "Epoch 124/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8275 - val_loss: 0.3642 - val_accuracy: 0.8450\n",
            "Epoch 125/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8313 - val_loss: 0.3669 - val_accuracy: 0.8350\n",
            "Epoch 126/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8263 - val_loss: 0.3612 - val_accuracy: 0.8350\n",
            "Epoch 127/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8275 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 128/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8300 - val_loss: 0.3670 - val_accuracy: 0.8350\n",
            "Epoch 129/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8313 - val_loss: 0.3674 - val_accuracy: 0.8350\n",
            "Epoch 130/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8263 - val_loss: 0.3591 - val_accuracy: 0.8350\n",
            "Epoch 131/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 132/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8325 - val_loss: 0.3650 - val_accuracy: 0.8350\n",
            "Epoch 133/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8300 - val_loss: 0.3612 - val_accuracy: 0.8350\n",
            "Epoch 134/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8300 - val_loss: 0.3684 - val_accuracy: 0.8350\n",
            "Epoch 135/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8275 - val_loss: 0.3596 - val_accuracy: 0.8450\n",
            "Epoch 136/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8288 - val_loss: 0.3693 - val_accuracy: 0.8350\n",
            "Epoch 137/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8300 - val_loss: 0.3621 - val_accuracy: 0.8450\n",
            "Epoch 138/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8325 - val_loss: 0.3669 - val_accuracy: 0.8350\n",
            "Epoch 139/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8288 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 140/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8350\n",
            "Epoch 141/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 142/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8250 - val_loss: 0.3624 - val_accuracy: 0.8350\n",
            "Epoch 143/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8313 - val_loss: 0.3641 - val_accuracy: 0.8350\n",
            "Epoch 144/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8313 - val_loss: 0.3641 - val_accuracy: 0.8350\n",
            "Epoch 145/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8275 - val_loss: 0.3688 - val_accuracy: 0.8350\n",
            "Epoch 146/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8313 - val_loss: 0.3658 - val_accuracy: 0.8350\n",
            "Epoch 147/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8275 - val_loss: 0.3578 - val_accuracy: 0.8350\n",
            "Epoch 148/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8250 - val_loss: 0.3657 - val_accuracy: 0.8350\n",
            "Epoch 149/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8325 - val_loss: 0.3616 - val_accuracy: 0.8350\n",
            "Epoch 150/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8313 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 151/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8300 - val_loss: 0.3651 - val_accuracy: 0.8350\n",
            "Epoch 152/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8263 - val_loss: 0.3691 - val_accuracy: 0.8350\n",
            "Epoch 153/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8250 - val_loss: 0.3615 - val_accuracy: 0.8400\n",
            "Epoch 154/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8300 - val_loss: 0.3624 - val_accuracy: 0.8350\n",
            "Epoch 155/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8250 - val_loss: 0.3642 - val_accuracy: 0.8350\n",
            "Epoch 156/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8275 - val_loss: 0.3571 - val_accuracy: 0.8350\n",
            "Epoch 157/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8288 - val_loss: 0.3643 - val_accuracy: 0.8350\n",
            "Epoch 158/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8288 - val_loss: 0.3658 - val_accuracy: 0.8350\n",
            "Epoch 159/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8275 - val_loss: 0.3573 - val_accuracy: 0.8350\n",
            "Epoch 160/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8238 - val_loss: 0.3565 - val_accuracy: 0.8350\n",
            "Epoch 161/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8275 - val_loss: 0.3610 - val_accuracy: 0.8350\n",
            "Epoch 162/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8300 - val_loss: 0.3618 - val_accuracy: 0.8350\n",
            "Epoch 163/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8275 - val_loss: 0.3665 - val_accuracy: 0.8350\n",
            "Epoch 164/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8288 - val_loss: 0.3604 - val_accuracy: 0.8350\n",
            "Epoch 165/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8313 - val_loss: 0.3600 - val_accuracy: 0.8350\n",
            "Epoch 166/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8350\n",
            "Epoch 167/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8250 - val_loss: 0.3661 - val_accuracy: 0.8350\n",
            "Epoch 168/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8275 - val_loss: 0.3614 - val_accuracy: 0.8350\n",
            "Epoch 169/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8288 - val_loss: 0.3593 - val_accuracy: 0.8350\n",
            "Epoch 170/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8288 - val_loss: 0.3708 - val_accuracy: 0.8350\n",
            "Epoch 171/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8300 - val_loss: 0.3672 - val_accuracy: 0.8350\n",
            "Epoch 172/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8275 - val_loss: 0.3644 - val_accuracy: 0.8400\n",
            "Epoch 173/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8300 - val_loss: 0.3644 - val_accuracy: 0.8350\n",
            "Epoch 174/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8263 - val_loss: 0.3651 - val_accuracy: 0.8350\n",
            "Epoch 175/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8275 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
            "Epoch 176/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8288 - val_loss: 0.3647 - val_accuracy: 0.8350\n",
            "Epoch 177/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8313 - val_loss: 0.3608 - val_accuracy: 0.8350\n",
            "Epoch 178/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8275 - val_loss: 0.3616 - val_accuracy: 0.8400\n",
            "Epoch 179/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8300 - val_loss: 0.3660 - val_accuracy: 0.8350\n",
            "Epoch 180/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8313 - val_loss: 0.3602 - val_accuracy: 0.8350\n",
            "Epoch 181/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8275 - val_loss: 0.3625 - val_accuracy: 0.8350\n",
            "Epoch 182/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8225 - val_loss: 0.3651 - val_accuracy: 0.8350\n",
            "Epoch 183/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8275 - val_loss: 0.3707 - val_accuracy: 0.8350\n",
            "Epoch 184/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8313 - val_loss: 0.3650 - val_accuracy: 0.8350\n",
            "Epoch 185/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8300 - val_loss: 0.3624 - val_accuracy: 0.8350\n",
            "Epoch 186/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8263 - val_loss: 0.3638 - val_accuracy: 0.8350\n",
            "Epoch 187/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8263 - val_loss: 0.3628 - val_accuracy: 0.8350\n",
            "Epoch 188/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8300 - val_loss: 0.3669 - val_accuracy: 0.8350\n",
            "Epoch 189/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8263 - val_loss: 0.3585 - val_accuracy: 0.8350\n",
            "Epoch 190/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8250 - val_loss: 0.3639 - val_accuracy: 0.8350\n",
            "Epoch 191/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8288 - val_loss: 0.3654 - val_accuracy: 0.8350\n",
            "Epoch 192/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8275 - val_loss: 0.3592 - val_accuracy: 0.8350\n",
            "Epoch 193/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8288 - val_loss: 0.3708 - val_accuracy: 0.8350\n",
            "Epoch 194/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8288 - val_loss: 0.3588 - val_accuracy: 0.8350\n",
            "Epoch 195/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8313 - val_loss: 0.3688 - val_accuracy: 0.8350\n",
            "Epoch 196/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8275 - val_loss: 0.3632 - val_accuracy: 0.8350\n",
            "Epoch 197/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8313 - val_loss: 0.3589 - val_accuracy: 0.8350\n",
            "Epoch 198/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8288 - val_loss: 0.3672 - val_accuracy: 0.8350\n",
            "Epoch 199/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8263 - val_loss: 0.3629 - val_accuracy: 0.8350\n",
            "Epoch 200/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3993 - accuracy: 0.8300 - val_loss: 0.3629 - val_accuracy: 0.8400\n",
            "Epoch 201/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8300 - val_loss: 0.3600 - val_accuracy: 0.8350\n",
            "Epoch 202/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8250 - val_loss: 0.3659 - val_accuracy: 0.8400\n",
            "Epoch 203/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8275 - val_loss: 0.3615 - val_accuracy: 0.8400\n",
            "Epoch 204/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8275 - val_loss: 0.3627 - val_accuracy: 0.8350\n",
            "Epoch 205/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3986 - accuracy: 0.8275 - val_loss: 0.3624 - val_accuracy: 0.8350\n",
            "Epoch 206/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3992 - accuracy: 0.8300 - val_loss: 0.3602 - val_accuracy: 0.8350\n",
            "Epoch 207/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8263 - val_loss: 0.3678 - val_accuracy: 0.8350\n",
            "Epoch 208/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8275 - val_loss: 0.3625 - val_accuracy: 0.8350\n",
            "Epoch 209/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8300 - val_loss: 0.3625 - val_accuracy: 0.8350\n",
            "Epoch 210/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8300 - val_loss: 0.3648 - val_accuracy: 0.8350\n",
            "Epoch 211/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3976 - accuracy: 0.8288 - val_loss: 0.3650 - val_accuracy: 0.8350\n",
            "Epoch 212/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8288 - val_loss: 0.3625 - val_accuracy: 0.8350\n",
            "Epoch 213/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8275 - val_loss: 0.3621 - val_accuracy: 0.8350\n",
            "Epoch 214/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8288 - val_loss: 0.3651 - val_accuracy: 0.8350\n",
            "Epoch 215/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8288 - val_loss: 0.3628 - val_accuracy: 0.8350\n",
            "Epoch 216/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8300 - val_loss: 0.3594 - val_accuracy: 0.8350\n",
            "Epoch 217/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8250 - val_loss: 0.3684 - val_accuracy: 0.8350\n",
            "Epoch 218/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8275 - val_loss: 0.3666 - val_accuracy: 0.8350\n",
            "Epoch 219/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8213 - val_loss: 0.3572 - val_accuracy: 0.8350\n",
            "Epoch 220/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8250 - val_loss: 0.3678 - val_accuracy: 0.8350\n",
            "Epoch 221/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8350 - val_loss: 0.3592 - val_accuracy: 0.8350\n",
            "Epoch 222/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8288 - val_loss: 0.3593 - val_accuracy: 0.8400\n",
            "Epoch 223/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8275 - val_loss: 0.3673 - val_accuracy: 0.8350\n",
            "Epoch 224/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8275 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
            "Epoch 225/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8288 - val_loss: 0.3661 - val_accuracy: 0.8350\n",
            "Epoch 226/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8263 - val_loss: 0.3698 - val_accuracy: 0.8350\n",
            "Epoch 227/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8300 - val_loss: 0.3576 - val_accuracy: 0.8350\n",
            "Epoch 228/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8288 - val_loss: 0.3618 - val_accuracy: 0.8350\n",
            "Epoch 229/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8275 - val_loss: 0.3665 - val_accuracy: 0.8400\n",
            "Epoch 230/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8275 - val_loss: 0.3717 - val_accuracy: 0.8350\n",
            "Epoch 231/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8313 - val_loss: 0.3650 - val_accuracy: 0.8350\n",
            "Epoch 232/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8300 - val_loss: 0.3640 - val_accuracy: 0.8350\n",
            "Epoch 233/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8238 - val_loss: 0.3652 - val_accuracy: 0.8350\n",
            "Epoch 234/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8300 - val_loss: 0.3647 - val_accuracy: 0.8350\n",
            "Epoch 235/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8288 - val_loss: 0.3627 - val_accuracy: 0.8350\n",
            "Epoch 236/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8275 - val_loss: 0.3639 - val_accuracy: 0.8400\n",
            "Epoch 237/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8300 - val_loss: 0.3629 - val_accuracy: 0.8350\n",
            "Epoch 238/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8225 - val_loss: 0.3667 - val_accuracy: 0.8350\n",
            "Epoch 239/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8225 - val_loss: 0.3737 - val_accuracy: 0.8350\n",
            "Epoch 240/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8288 - val_loss: 0.3636 - val_accuracy: 0.8350\n",
            "Epoch 241/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8313 - val_loss: 0.3641 - val_accuracy: 0.8350\n",
            "Epoch 242/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8275 - val_loss: 0.3623 - val_accuracy: 0.8350\n",
            "Epoch 243/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8275 - val_loss: 0.3644 - val_accuracy: 0.8350\n",
            "Epoch 244/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8288 - val_loss: 0.3672 - val_accuracy: 0.8350\n",
            "Epoch 245/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8275 - val_loss: 0.3683 - val_accuracy: 0.8350\n",
            "Epoch 246/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8288 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
            "Epoch 247/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8263 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 248/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8263 - val_loss: 0.3649 - val_accuracy: 0.8350\n",
            "Epoch 249/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8288 - val_loss: 0.3617 - val_accuracy: 0.8350\n",
            "Epoch 250/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8263 - val_loss: 0.3640 - val_accuracy: 0.8350\n",
            "Epoch 251/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8263 - val_loss: 0.3655 - val_accuracy: 0.8350\n",
            "Epoch 252/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8288 - val_loss: 0.3641 - val_accuracy: 0.8400\n",
            "Epoch 253/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8288 - val_loss: 0.3609 - val_accuracy: 0.8350\n",
            "Epoch 254/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8300 - val_loss: 0.3662 - val_accuracy: 0.8350\n",
            "Epoch 255/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8300 - val_loss: 0.3644 - val_accuracy: 0.8350\n",
            "Epoch 256/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8288 - val_loss: 0.3665 - val_accuracy: 0.8350\n",
            "Epoch 257/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8275 - val_loss: 0.3692 - val_accuracy: 0.8400\n",
            "Epoch 258/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8250 - val_loss: 0.3706 - val_accuracy: 0.8350\n",
            "Epoch 259/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8263 - val_loss: 0.3645 - val_accuracy: 0.8400\n",
            "Epoch 260/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8263 - val_loss: 0.3665 - val_accuracy: 0.8350\n",
            "Epoch 261/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8300 - val_loss: 0.3740 - val_accuracy: 0.8350\n",
            "Epoch 262/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8313 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 263/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8288 - val_loss: 0.3609 - val_accuracy: 0.8400\n",
            "Epoch 264/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8275 - val_loss: 0.3670 - val_accuracy: 0.8350\n",
            "Epoch 265/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8313 - val_loss: 0.3632 - val_accuracy: 0.8350\n",
            "Epoch 266/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8288 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
            "Epoch 267/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8300 - val_loss: 0.3734 - val_accuracy: 0.8400\n",
            "Epoch 268/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8313 - val_loss: 0.3630 - val_accuracy: 0.8400\n",
            "Epoch 269/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8263 - val_loss: 0.3663 - val_accuracy: 0.8350\n",
            "Epoch 270/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8263 - val_loss: 0.3648 - val_accuracy: 0.8350\n",
            "Epoch 271/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8288 - val_loss: 0.3676 - val_accuracy: 0.8400\n",
            "Epoch 272/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8263 - val_loss: 0.3701 - val_accuracy: 0.8400\n",
            "Epoch 273/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8275 - val_loss: 0.3660 - val_accuracy: 0.8350\n",
            "Epoch 274/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8263 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 275/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8338 - val_loss: 0.3605 - val_accuracy: 0.8400\n",
            "Epoch 276/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8250 - val_loss: 0.3699 - val_accuracy: 0.8350\n",
            "Epoch 277/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8300 - val_loss: 0.3655 - val_accuracy: 0.8400\n",
            "Epoch 278/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8275 - val_loss: 0.3662 - val_accuracy: 0.8350\n",
            "Epoch 279/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8275 - val_loss: 0.3599 - val_accuracy: 0.8400\n",
            "Epoch 280/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8338 - val_loss: 0.3695 - val_accuracy: 0.8450\n",
            "Epoch 281/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8288 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 282/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8288 - val_loss: 0.3658 - val_accuracy: 0.8350\n",
            "Epoch 283/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8288 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 284/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8275 - val_loss: 0.3613 - val_accuracy: 0.8400\n",
            "Epoch 285/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8263 - val_loss: 0.3682 - val_accuracy: 0.8400\n",
            "Epoch 286/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8288 - val_loss: 0.3674 - val_accuracy: 0.8350\n",
            "Epoch 287/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8300 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 288/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8288 - val_loss: 0.3633 - val_accuracy: 0.8400\n",
            "Epoch 289/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8263 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 290/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8300 - val_loss: 0.3644 - val_accuracy: 0.8400\n",
            "Epoch 291/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8250 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
            "Epoch 292/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8300 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
            "Epoch 293/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8313 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
            "Epoch 294/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8263 - val_loss: 0.3637 - val_accuracy: 0.8350\n",
            "Epoch 295/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8300 - val_loss: 0.3676 - val_accuracy: 0.8400\n",
            "Epoch 296/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8288 - val_loss: 0.3656 - val_accuracy: 0.8350\n",
            "Epoch 297/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8250 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
            "Epoch 298/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8288 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 299/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8288 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 300/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8300 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 301/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8275 - val_loss: 0.3628 - val_accuracy: 0.8400\n",
            "Epoch 302/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8275 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 303/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8275 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
            "Epoch 304/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8288 - val_loss: 0.3626 - val_accuracy: 0.8400\n",
            "Epoch 305/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8250 - val_loss: 0.3608 - val_accuracy: 0.8400\n",
            "Epoch 306/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8213 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 307/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8288 - val_loss: 0.3723 - val_accuracy: 0.8400\n",
            "Epoch 308/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8313 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 309/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8288 - val_loss: 0.3614 - val_accuracy: 0.8400\n",
            "Epoch 310/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8225 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 311/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8288 - val_loss: 0.3676 - val_accuracy: 0.8400\n",
            "Epoch 312/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8313 - val_loss: 0.3653 - val_accuracy: 0.8400\n",
            "Epoch 313/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8238 - val_loss: 0.3681 - val_accuracy: 0.8400\n",
            "Epoch 314/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8300 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 315/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8250 - val_loss: 0.3609 - val_accuracy: 0.8450\n",
            "Epoch 316/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8313 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
            "Epoch 317/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8238 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 318/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8300 - val_loss: 0.3672 - val_accuracy: 0.8400\n",
            "Epoch 319/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8238 - val_loss: 0.3583 - val_accuracy: 0.8400\n",
            "Epoch 320/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8275 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 321/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8300 - val_loss: 0.3635 - val_accuracy: 0.8400\n",
            "Epoch 322/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8225 - val_loss: 0.3678 - val_accuracy: 0.8350\n",
            "Epoch 323/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8325 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 324/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8250 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 325/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8225 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 326/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8275 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 327/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8263 - val_loss: 0.3664 - val_accuracy: 0.8400\n",
            "Epoch 328/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8300 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 329/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8263 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 330/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8300 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
            "Epoch 331/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8288 - val_loss: 0.3679 - val_accuracy: 0.8400\n",
            "Epoch 332/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8263 - val_loss: 0.3627 - val_accuracy: 0.8450\n",
            "Epoch 333/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8288 - val_loss: 0.3694 - val_accuracy: 0.8400\n",
            "Epoch 334/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8238 - val_loss: 0.3631 - val_accuracy: 0.8400\n",
            "Epoch 335/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8263 - val_loss: 0.3744 - val_accuracy: 0.8450\n",
            "Epoch 336/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8275 - val_loss: 0.3649 - val_accuracy: 0.8400\n",
            "Epoch 337/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8313 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 338/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8300 - val_loss: 0.3608 - val_accuracy: 0.8400\n",
            "Epoch 339/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8300 - val_loss: 0.3712 - val_accuracy: 0.8400\n",
            "Epoch 340/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8300 - val_loss: 0.3648 - val_accuracy: 0.8400\n",
            "Epoch 341/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8275 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 342/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8300 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 343/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8288 - val_loss: 0.3676 - val_accuracy: 0.8400\n",
            "Epoch 344/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8288 - val_loss: 0.3679 - val_accuracy: 0.8450\n",
            "Epoch 345/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8288 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
            "Epoch 346/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8288 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 347/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8263 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 348/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8325 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 349/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8288 - val_loss: 0.3607 - val_accuracy: 0.8400\n",
            "Epoch 350/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8300 - val_loss: 0.3631 - val_accuracy: 0.8400\n",
            "Epoch 351/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8288 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
            "Epoch 352/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8325 - val_loss: 0.3670 - val_accuracy: 0.8400\n",
            "Epoch 353/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8263 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 354/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8213 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 355/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8300 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 356/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8250 - val_loss: 0.3682 - val_accuracy: 0.8450\n",
            "Epoch 357/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8288 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 358/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8275 - val_loss: 0.3650 - val_accuracy: 0.8450\n",
            "Epoch 359/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8238 - val_loss: 0.3629 - val_accuracy: 0.8400\n",
            "Epoch 360/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8263 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 361/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8238 - val_loss: 0.3686 - val_accuracy: 0.8400\n",
            "Epoch 362/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8313 - val_loss: 0.3630 - val_accuracy: 0.8400\n",
            "Epoch 363/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8288 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
            "Epoch 364/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8263 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
            "Epoch 365/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8313 - val_loss: 0.3742 - val_accuracy: 0.8400\n",
            "Epoch 366/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8300 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 367/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8275 - val_loss: 0.3669 - val_accuracy: 0.8450\n",
            "Epoch 368/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8288 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 369/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8263 - val_loss: 0.3684 - val_accuracy: 0.8350\n",
            "Epoch 370/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8263 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 371/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8275 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
            "Epoch 372/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8263 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 373/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8263 - val_loss: 0.3684 - val_accuracy: 0.8400\n",
            "Epoch 374/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8300 - val_loss: 0.3612 - val_accuracy: 0.8400\n",
            "Epoch 375/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8263 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 376/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8288 - val_loss: 0.3619 - val_accuracy: 0.8400\n",
            "Epoch 377/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8250 - val_loss: 0.3705 - val_accuracy: 0.8450\n",
            "Epoch 378/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8263 - val_loss: 0.3633 - val_accuracy: 0.8400\n",
            "Epoch 379/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8313 - val_loss: 0.3653 - val_accuracy: 0.8400\n",
            "Epoch 380/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8238 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 381/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8313 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 382/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8275 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 383/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8300 - val_loss: 0.3707 - val_accuracy: 0.8450\n",
            "Epoch 384/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8300 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 385/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8238 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 386/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8300 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
            "Epoch 387/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8275 - val_loss: 0.3680 - val_accuracy: 0.8450\n",
            "Epoch 388/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8288 - val_loss: 0.3704 - val_accuracy: 0.8400\n",
            "Epoch 389/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8288 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 390/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8288 - val_loss: 0.3653 - val_accuracy: 0.8450\n",
            "Epoch 391/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8313 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
            "Epoch 392/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8300 - val_loss: 0.3631 - val_accuracy: 0.8400\n",
            "Epoch 393/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8300 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 394/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8275 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 395/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8300 - val_loss: 0.3639 - val_accuracy: 0.8400\n",
            "Epoch 396/1000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.3938 - accuracy: 0.8313 - val_loss: 0.3704 - val_accuracy: 0.8400\n",
            "Epoch 397/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3934 - accuracy: 0.8288 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
            "Epoch 398/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8275 - val_loss: 0.3612 - val_accuracy: 0.8400\n",
            "Epoch 399/1000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.8250 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
            "Epoch 400/1000\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.3956 - accuracy: 0.8250 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 401/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8313 - val_loss: 0.3725 - val_accuracy: 0.8450\n",
            "Epoch 402/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8263 - val_loss: 0.3676 - val_accuracy: 0.8400\n",
            "Epoch 403/1000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.3932 - accuracy: 0.8313 - val_loss: 0.3723 - val_accuracy: 0.8450\n",
            "Epoch 404/1000\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.3953 - accuracy: 0.8263 - val_loss: 0.3745 - val_accuracy: 0.8400\n",
            "Epoch 405/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.8275 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
            "Epoch 406/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8275 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 407/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3941 - accuracy: 0.8300 - val_loss: 0.3705 - val_accuracy: 0.8400\n",
            "Epoch 408/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8263 - val_loss: 0.3672 - val_accuracy: 0.8450\n",
            "Epoch 409/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8238 - val_loss: 0.3672 - val_accuracy: 0.8450\n",
            "Epoch 410/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 411/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8275 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 412/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.8238 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 413/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8325 - val_loss: 0.3705 - val_accuracy: 0.8450\n",
            "Epoch 414/1000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.8300 - val_loss: 0.3643 - val_accuracy: 0.8450\n",
            "Epoch 415/1000\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.3943 - accuracy: 0.8288 - val_loss: 0.3645 - val_accuracy: 0.8400\n",
            "Epoch 416/1000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8313 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 417/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8300 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 418/1000\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.3926 - accuracy: 0.8263 - val_loss: 0.3649 - val_accuracy: 0.8400\n",
            "Epoch 419/1000\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3932 - accuracy: 0.8300 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
            "Epoch 420/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8263 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
            "Epoch 421/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8275 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
            "Epoch 422/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8313 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 423/1000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.3960 - accuracy: 0.8213 - val_loss: 0.3655 - val_accuracy: 0.8400\n",
            "Epoch 424/1000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.8275 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 425/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8263 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 426/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8313 - val_loss: 0.3641 - val_accuracy: 0.8400\n",
            "Epoch 427/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8288 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 428/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8288 - val_loss: 0.3702 - val_accuracy: 0.8450\n",
            "Epoch 429/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8238 - val_loss: 0.3687 - val_accuracy: 0.8350\n",
            "Epoch 430/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8300 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 431/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8275 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 432/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8288 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 433/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8250 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 434/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8300 - val_loss: 0.3677 - val_accuracy: 0.8400\n",
            "Epoch 435/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8263 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 436/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8263 - val_loss: 0.3748 - val_accuracy: 0.8400\n",
            "Epoch 437/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8288 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 438/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8250 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 439/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8275 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
            "Epoch 440/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8363 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 441/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8213 - val_loss: 0.3721 - val_accuracy: 0.8450\n",
            "Epoch 442/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8288 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 443/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8275 - val_loss: 0.3655 - val_accuracy: 0.8450\n",
            "Epoch 444/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8275 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 445/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8275 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
            "Epoch 446/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8313 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
            "Epoch 447/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8288 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 448/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8288 - val_loss: 0.3661 - val_accuracy: 0.8400\n",
            "Epoch 449/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8263 - val_loss: 0.3757 - val_accuracy: 0.8400\n",
            "Epoch 450/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8263 - val_loss: 0.3661 - val_accuracy: 0.8400\n",
            "Epoch 451/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8275 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
            "Epoch 452/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8325 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 453/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8275 - val_loss: 0.3674 - val_accuracy: 0.8450\n",
            "Epoch 454/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8275 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 455/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8375 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 456/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8250 - val_loss: 0.3677 - val_accuracy: 0.8450\n",
            "Epoch 457/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8263 - val_loss: 0.3680 - val_accuracy: 0.8400\n",
            "Epoch 458/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8313 - val_loss: 0.3717 - val_accuracy: 0.8350\n",
            "Epoch 459/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8300 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 460/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8325 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
            "Epoch 461/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8250 - val_loss: 0.3674 - val_accuracy: 0.8350\n",
            "Epoch 462/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.3628 - val_accuracy: 0.8450\n",
            "Epoch 463/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8275 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
            "Epoch 464/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8288 - val_loss: 0.3633 - val_accuracy: 0.8400\n",
            "Epoch 465/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8263 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 466/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8325 - val_loss: 0.3706 - val_accuracy: 0.8400\n",
            "Epoch 467/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8250 - val_loss: 0.3630 - val_accuracy: 0.8400\n",
            "Epoch 468/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8263 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
            "Epoch 469/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8300 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 470/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8275 - val_loss: 0.3679 - val_accuracy: 0.8400\n",
            "Epoch 471/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8263 - val_loss: 0.3754 - val_accuracy: 0.8400\n",
            "Epoch 472/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8250 - val_loss: 0.3613 - val_accuracy: 0.8400\n",
            "Epoch 473/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8288 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 474/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3747 - val_accuracy: 0.8400\n",
            "Epoch 475/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8250 - val_loss: 0.3714 - val_accuracy: 0.8350\n",
            "Epoch 476/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8363 - val_loss: 0.3666 - val_accuracy: 0.8400\n",
            "Epoch 477/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8300 - val_loss: 0.3646 - val_accuracy: 0.8400\n",
            "Epoch 478/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8238 - val_loss: 0.3723 - val_accuracy: 0.8450\n",
            "Epoch 479/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8263 - val_loss: 0.3723 - val_accuracy: 0.8400\n",
            "Epoch 480/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8350 - val_loss: 0.3699 - val_accuracy: 0.8400\n",
            "Epoch 481/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8250 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 482/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8313 - val_loss: 0.3638 - val_accuracy: 0.8450\n",
            "Epoch 483/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8288 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
            "Epoch 484/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8250 - val_loss: 0.3631 - val_accuracy: 0.8400\n",
            "Epoch 485/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8250 - val_loss: 0.3715 - val_accuracy: 0.8450\n",
            "Epoch 486/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8288 - val_loss: 0.3707 - val_accuracy: 0.8450\n",
            "Epoch 487/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8325 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 488/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3933 - accuracy: 0.8313 - val_loss: 0.3667 - val_accuracy: 0.8400\n",
            "Epoch 489/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8250 - val_loss: 0.3672 - val_accuracy: 0.8450\n",
            "Epoch 490/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8275 - val_loss: 0.3626 - val_accuracy: 0.8450\n",
            "Epoch 491/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8225 - val_loss: 0.3753 - val_accuracy: 0.8400\n",
            "Epoch 492/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8263 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
            "Epoch 493/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8263 - val_loss: 0.3677 - val_accuracy: 0.8450\n",
            "Epoch 494/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3920 - accuracy: 0.8300 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
            "Epoch 495/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.3680 - val_accuracy: 0.8400\n",
            "Epoch 496/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8300 - val_loss: 0.3750 - val_accuracy: 0.8400\n",
            "Epoch 497/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8313 - val_loss: 0.3727 - val_accuracy: 0.8450\n",
            "Epoch 498/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8275 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
            "Epoch 499/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8288 - val_loss: 0.3739 - val_accuracy: 0.8400\n",
            "Epoch 500/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8263 - val_loss: 0.3691 - val_accuracy: 0.8450\n",
            "Epoch 501/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8288 - val_loss: 0.3749 - val_accuracy: 0.8450\n",
            "Epoch 502/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8250 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 503/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8350 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 504/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8288 - val_loss: 0.3701 - val_accuracy: 0.8400\n",
            "Epoch 505/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8263 - val_loss: 0.3654 - val_accuracy: 0.8450\n",
            "Epoch 506/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8275 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 507/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8300 - val_loss: 0.3699 - val_accuracy: 0.8400\n",
            "Epoch 508/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8300 - val_loss: 0.3689 - val_accuracy: 0.8400\n",
            "Epoch 509/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8275 - val_loss: 0.3726 - val_accuracy: 0.8400\n",
            "Epoch 510/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8325 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 511/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3675 - val_accuracy: 0.8400\n",
            "Epoch 512/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8313 - val_loss: 0.3654 - val_accuracy: 0.8400\n",
            "Epoch 513/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8275 - val_loss: 0.3687 - val_accuracy: 0.8450\n",
            "Epoch 514/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 515/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8238 - val_loss: 0.3613 - val_accuracy: 0.8400\n",
            "Epoch 516/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8325 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 517/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8275 - val_loss: 0.3711 - val_accuracy: 0.8400\n",
            "Epoch 518/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8288 - val_loss: 0.3670 - val_accuracy: 0.8400\n",
            "Epoch 519/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8275 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 520/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8300 - val_loss: 0.3682 - val_accuracy: 0.8450\n",
            "Epoch 521/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8275 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 522/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8275 - val_loss: 0.3725 - val_accuracy: 0.8450\n",
            "Epoch 523/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8313 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 524/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8288 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
            "Epoch 525/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8313 - val_loss: 0.3712 - val_accuracy: 0.8400\n",
            "Epoch 526/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8313 - val_loss: 0.3736 - val_accuracy: 0.8400\n",
            "Epoch 527/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3692 - val_accuracy: 0.8400\n",
            "Epoch 528/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8263 - val_loss: 0.3739 - val_accuracy: 0.8450\n",
            "Epoch 529/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
            "Epoch 530/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8263 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 531/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8313 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
            "Epoch 532/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8275 - val_loss: 0.3770 - val_accuracy: 0.8400\n",
            "Epoch 533/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8288 - val_loss: 0.3726 - val_accuracy: 0.8400\n",
            "Epoch 534/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8263 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 535/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8300 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 536/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8250 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 537/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8288 - val_loss: 0.3706 - val_accuracy: 0.8450\n",
            "Epoch 538/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8263 - val_loss: 0.3697 - val_accuracy: 0.8400\n",
            "Epoch 539/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8325 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 540/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8263 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
            "Epoch 541/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8288 - val_loss: 0.3712 - val_accuracy: 0.8400\n",
            "Epoch 542/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8250 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 543/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8300 - val_loss: 0.3685 - val_accuracy: 0.8450\n",
            "Epoch 544/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8275 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
            "Epoch 545/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8325 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
            "Epoch 546/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8275 - val_loss: 0.3658 - val_accuracy: 0.8450\n",
            "Epoch 547/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8275 - val_loss: 0.3698 - val_accuracy: 0.8450\n",
            "Epoch 548/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8313 - val_loss: 0.3686 - val_accuracy: 0.8400\n",
            "Epoch 549/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8263 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 550/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8288 - val_loss: 0.3732 - val_accuracy: 0.8450\n",
            "Epoch 551/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8275 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
            "Epoch 552/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8238 - val_loss: 0.3810 - val_accuracy: 0.8400\n",
            "Epoch 553/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8288 - val_loss: 0.3734 - val_accuracy: 0.8450\n",
            "Epoch 554/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8313 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 555/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8275 - val_loss: 0.3761 - val_accuracy: 0.8400\n",
            "Epoch 556/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8288 - val_loss: 0.3770 - val_accuracy: 0.8350\n",
            "Epoch 557/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8325 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
            "Epoch 558/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8288 - val_loss: 0.3690 - val_accuracy: 0.8450\n",
            "Epoch 559/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8300 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 560/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8263 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 561/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8263 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 562/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8300 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 563/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8288 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 564/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8313 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
            "Epoch 565/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8288 - val_loss: 0.3654 - val_accuracy: 0.8400\n",
            "Epoch 566/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8263 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
            "Epoch 567/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3786 - val_accuracy: 0.8400\n",
            "Epoch 568/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8338 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 569/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8325 - val_loss: 0.3701 - val_accuracy: 0.8400\n",
            "Epoch 570/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8275 - val_loss: 0.3659 - val_accuracy: 0.8400\n",
            "Epoch 571/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8300 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 572/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3680 - val_accuracy: 0.8450\n",
            "Epoch 573/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8325 - val_loss: 0.3670 - val_accuracy: 0.8400\n",
            "Epoch 574/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8250 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 575/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3914 - accuracy: 0.8325 - val_loss: 0.3708 - val_accuracy: 0.8450\n",
            "Epoch 576/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8238 - val_loss: 0.3738 - val_accuracy: 0.8450\n",
            "Epoch 577/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.3648 - val_accuracy: 0.8450\n",
            "Epoch 578/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8263 - val_loss: 0.3745 - val_accuracy: 0.8450\n",
            "Epoch 579/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3916 - accuracy: 0.8275 - val_loss: 0.3660 - val_accuracy: 0.8450\n",
            "Epoch 580/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8275 - val_loss: 0.3760 - val_accuracy: 0.8450\n",
            "Epoch 581/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8275 - val_loss: 0.3738 - val_accuracy: 0.8450\n",
            "Epoch 582/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8313 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
            "Epoch 583/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8275 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 584/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8300 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
            "Epoch 585/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3917 - accuracy: 0.8288 - val_loss: 0.3746 - val_accuracy: 0.8400\n",
            "Epoch 586/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8325 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
            "Epoch 587/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8288 - val_loss: 0.3735 - val_accuracy: 0.8400\n",
            "Epoch 588/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8300 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 589/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8238 - val_loss: 0.3736 - val_accuracy: 0.8400\n",
            "Epoch 590/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8300 - val_loss: 0.3695 - val_accuracy: 0.8450\n",
            "Epoch 591/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8263 - val_loss: 0.3641 - val_accuracy: 0.8400\n",
            "Epoch 592/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8275 - val_loss: 0.3787 - val_accuracy: 0.8450\n",
            "Epoch 593/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8325 - val_loss: 0.3712 - val_accuracy: 0.8400\n",
            "Epoch 594/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8325 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 595/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8250 - val_loss: 0.3721 - val_accuracy: 0.8450\n",
            "Epoch 596/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.3698 - val_accuracy: 0.8450\n",
            "Epoch 597/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8288 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 598/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8275 - val_loss: 0.3735 - val_accuracy: 0.8450\n",
            "Epoch 599/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8288 - val_loss: 0.3726 - val_accuracy: 0.8400\n",
            "Epoch 600/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8325 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
            "Epoch 601/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.3727 - val_accuracy: 0.8450\n",
            "Epoch 602/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8275 - val_loss: 0.3698 - val_accuracy: 0.8450\n",
            "Epoch 603/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8313 - val_loss: 0.3784 - val_accuracy: 0.8400\n",
            "Epoch 604/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8275 - val_loss: 0.3682 - val_accuracy: 0.8400\n",
            "Epoch 605/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8313 - val_loss: 0.3748 - val_accuracy: 0.8400\n",
            "Epoch 606/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8288 - val_loss: 0.3682 - val_accuracy: 0.8450\n",
            "Epoch 607/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8300 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
            "Epoch 608/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8275 - val_loss: 0.3682 - val_accuracy: 0.8400\n",
            "Epoch 609/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8288 - val_loss: 0.3753 - val_accuracy: 0.8450\n",
            "Epoch 610/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8300 - val_loss: 0.3716 - val_accuracy: 0.8450\n",
            "Epoch 611/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8288 - val_loss: 0.3706 - val_accuracy: 0.8450\n",
            "Epoch 612/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8275 - val_loss: 0.3665 - val_accuracy: 0.8450\n",
            "Epoch 613/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8325 - val_loss: 0.3743 - val_accuracy: 0.8450\n",
            "Epoch 614/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8275 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
            "Epoch 615/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3752 - val_accuracy: 0.8450\n",
            "Epoch 616/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8300 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 617/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8263 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 618/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8250 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 619/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8313 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
            "Epoch 620/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8313 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 621/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8325 - val_loss: 0.3672 - val_accuracy: 0.8450\n",
            "Epoch 622/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8250 - val_loss: 0.3715 - val_accuracy: 0.8400\n",
            "Epoch 623/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8350 - val_loss: 0.3692 - val_accuracy: 0.8400\n",
            "Epoch 624/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8275 - val_loss: 0.3710 - val_accuracy: 0.8450\n",
            "Epoch 625/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8275 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 626/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8313 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
            "Epoch 627/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8275 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 628/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8263 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
            "Epoch 629/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8263 - val_loss: 0.3689 - val_accuracy: 0.8400\n",
            "Epoch 630/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8288 - val_loss: 0.3710 - val_accuracy: 0.8450\n",
            "Epoch 631/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8313 - val_loss: 0.3766 - val_accuracy: 0.8450\n",
            "Epoch 632/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8338 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 633/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8275 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
            "Epoch 634/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8288 - val_loss: 0.3681 - val_accuracy: 0.8450\n",
            "Epoch 635/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8263 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
            "Epoch 636/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8300 - val_loss: 0.3751 - val_accuracy: 0.8400\n",
            "Epoch 637/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8263 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 638/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8275 - val_loss: 0.3706 - val_accuracy: 0.8400\n",
            "Epoch 639/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8288 - val_loss: 0.3758 - val_accuracy: 0.8450\n",
            "Epoch 640/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8213 - val_loss: 0.3654 - val_accuracy: 0.8450\n",
            "Epoch 641/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8313 - val_loss: 0.3715 - val_accuracy: 0.8400\n",
            "Epoch 642/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3779 - val_accuracy: 0.8400\n",
            "Epoch 643/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8288 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 644/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8275 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 645/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8300 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
            "Epoch 646/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8313 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
            "Epoch 647/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8288 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
            "Epoch 648/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8300 - val_loss: 0.3694 - val_accuracy: 0.8400\n",
            "Epoch 649/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8263 - val_loss: 0.3799 - val_accuracy: 0.8400\n",
            "Epoch 650/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8338 - val_loss: 0.3681 - val_accuracy: 0.8400\n",
            "Epoch 651/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.3772 - val_accuracy: 0.8450\n",
            "Epoch 652/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8288 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
            "Epoch 653/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8288 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
            "Epoch 654/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8263 - val_loss: 0.3743 - val_accuracy: 0.8450\n",
            "Epoch 655/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8325 - val_loss: 0.3716 - val_accuracy: 0.8450\n",
            "Epoch 656/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8263 - val_loss: 0.3711 - val_accuracy: 0.8450\n",
            "Epoch 657/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8263 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
            "Epoch 658/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8288 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 659/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8338 - val_loss: 0.3758 - val_accuracy: 0.8400\n",
            "Epoch 660/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8300 - val_loss: 0.3728 - val_accuracy: 0.8400\n",
            "Epoch 661/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8313 - val_loss: 0.3763 - val_accuracy: 0.8450\n",
            "Epoch 662/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8250 - val_loss: 0.3788 - val_accuracy: 0.8400\n",
            "Epoch 663/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8288 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 664/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8313 - val_loss: 0.3754 - val_accuracy: 0.8400\n",
            "Epoch 665/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8325 - val_loss: 0.3640 - val_accuracy: 0.8450\n",
            "Epoch 666/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8300 - val_loss: 0.3753 - val_accuracy: 0.8450\n",
            "Epoch 667/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8300 - val_loss: 0.3727 - val_accuracy: 0.8450\n",
            "Epoch 668/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8300 - val_loss: 0.3738 - val_accuracy: 0.8450\n",
            "Epoch 669/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 670/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8275 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 671/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8263 - val_loss: 0.3681 - val_accuracy: 0.8400\n",
            "Epoch 672/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8300 - val_loss: 0.3720 - val_accuracy: 0.8400\n",
            "Epoch 673/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8225 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
            "Epoch 674/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8363 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
            "Epoch 675/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8250 - val_loss: 0.3702 - val_accuracy: 0.8450\n",
            "Epoch 676/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8325 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
            "Epoch 677/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3908 - accuracy: 0.8263 - val_loss: 0.3732 - val_accuracy: 0.8450\n",
            "Epoch 678/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8313 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
            "Epoch 679/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3915 - accuracy: 0.8250 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
            "Epoch 680/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8313 - val_loss: 0.3675 - val_accuracy: 0.8400\n",
            "Epoch 681/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8275 - val_loss: 0.3697 - val_accuracy: 0.8450\n",
            "Epoch 682/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3928 - accuracy: 0.8313 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
            "Epoch 683/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8200 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 684/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8325 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
            "Epoch 685/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8275 - val_loss: 0.3649 - val_accuracy: 0.8400\n",
            "Epoch 686/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8288 - val_loss: 0.3763 - val_accuracy: 0.8450\n",
            "Epoch 687/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8275 - val_loss: 0.3756 - val_accuracy: 0.8450\n",
            "Epoch 688/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8313 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 689/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8300 - val_loss: 0.3774 - val_accuracy: 0.8400\n",
            "Epoch 690/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.3785 - val_accuracy: 0.8450\n",
            "Epoch 691/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8288 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 692/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8275 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
            "Epoch 693/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8263 - val_loss: 0.3674 - val_accuracy: 0.8450\n",
            "Epoch 694/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8263 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 695/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8300 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 696/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8300 - val_loss: 0.3737 - val_accuracy: 0.8450\n",
            "Epoch 697/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8238 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 698/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8288 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 699/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8275 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 700/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8313 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 701/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8288 - val_loss: 0.3760 - val_accuracy: 0.8450\n",
            "Epoch 702/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8275 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 703/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8275 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
            "Epoch 704/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8288 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 705/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8275 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 706/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8313 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 707/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8250 - val_loss: 0.3739 - val_accuracy: 0.8450\n",
            "Epoch 708/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8300 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 709/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
            "Epoch 710/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3779 - val_accuracy: 0.8450\n",
            "Epoch 711/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8300 - val_loss: 0.3684 - val_accuracy: 0.8400\n",
            "Epoch 712/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8313 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 713/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8250 - val_loss: 0.3789 - val_accuracy: 0.8450\n",
            "Epoch 714/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8300 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 715/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8275 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
            "Epoch 716/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8288 - val_loss: 0.3736 - val_accuracy: 0.8450\n",
            "Epoch 717/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8325 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
            "Epoch 718/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8275 - val_loss: 0.3702 - val_accuracy: 0.8400\n",
            "Epoch 719/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8300 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 720/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8288 - val_loss: 0.3705 - val_accuracy: 0.8450\n",
            "Epoch 721/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8263 - val_loss: 0.3675 - val_accuracy: 0.8450\n",
            "Epoch 722/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8288 - val_loss: 0.3772 - val_accuracy: 0.8400\n",
            "Epoch 723/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8275 - val_loss: 0.3712 - val_accuracy: 0.8450\n",
            "Epoch 724/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8238 - val_loss: 0.3742 - val_accuracy: 0.8400\n",
            "Epoch 725/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8313 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 726/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8238 - val_loss: 0.3742 - val_accuracy: 0.8400\n",
            "Epoch 727/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8313 - val_loss: 0.3762 - val_accuracy: 0.8450\n",
            "Epoch 728/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8300 - val_loss: 0.3729 - val_accuracy: 0.8400\n",
            "Epoch 729/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8300 - val_loss: 0.3697 - val_accuracy: 0.8400\n",
            "Epoch 730/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8263 - val_loss: 0.3749 - val_accuracy: 0.8400\n",
            "Epoch 731/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8325 - val_loss: 0.3760 - val_accuracy: 0.8450\n",
            "Epoch 732/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8263 - val_loss: 0.3648 - val_accuracy: 0.8400\n",
            "Epoch 733/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8313 - val_loss: 0.3765 - val_accuracy: 0.8400\n",
            "Epoch 734/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8263 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
            "Epoch 735/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8250 - val_loss: 0.3789 - val_accuracy: 0.8400\n",
            "Epoch 736/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8300 - val_loss: 0.3722 - val_accuracy: 0.8450\n",
            "Epoch 737/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8288 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 738/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8238 - val_loss: 0.3766 - val_accuracy: 0.8400\n",
            "Epoch 739/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8338 - val_loss: 0.3696 - val_accuracy: 0.8450\n",
            "Epoch 740/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8238 - val_loss: 0.3646 - val_accuracy: 0.8400\n",
            "Epoch 741/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8263 - val_loss: 0.3754 - val_accuracy: 0.8450\n",
            "Epoch 742/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8338 - val_loss: 0.3685 - val_accuracy: 0.8450\n",
            "Epoch 743/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8263 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 744/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8338 - val_loss: 0.3785 - val_accuracy: 0.8450\n",
            "Epoch 745/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8313 - val_loss: 0.3705 - val_accuracy: 0.8400\n",
            "Epoch 746/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8300 - val_loss: 0.3696 - val_accuracy: 0.8450\n",
            "Epoch 747/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8288 - val_loss: 0.3728 - val_accuracy: 0.8400\n",
            "Epoch 748/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8263 - val_loss: 0.3746 - val_accuracy: 0.8400\n",
            "Epoch 749/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8275 - val_loss: 0.3692 - val_accuracy: 0.8450\n",
            "Epoch 750/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8263 - val_loss: 0.3728 - val_accuracy: 0.8400\n",
            "Epoch 751/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8288 - val_loss: 0.3782 - val_accuracy: 0.8400\n",
            "Epoch 752/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8263 - val_loss: 0.3750 - val_accuracy: 0.8450\n",
            "Epoch 753/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8238 - val_loss: 0.3710 - val_accuracy: 0.8400\n",
            "Epoch 754/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8313 - val_loss: 0.3771 - val_accuracy: 0.8400\n",
            "Epoch 755/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8250 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 756/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8288 - val_loss: 0.3758 - val_accuracy: 0.8400\n",
            "Epoch 757/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8313 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 758/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8300 - val_loss: 0.3814 - val_accuracy: 0.8450\n",
            "Epoch 759/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8363 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
            "Epoch 760/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8250 - val_loss: 0.3755 - val_accuracy: 0.8400\n",
            "Epoch 761/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8300 - val_loss: 0.3690 - val_accuracy: 0.8450\n",
            "Epoch 762/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8250 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 763/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8313 - val_loss: 0.3756 - val_accuracy: 0.8450\n",
            "Epoch 764/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 765/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8288 - val_loss: 0.3702 - val_accuracy: 0.8400\n",
            "Epoch 766/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8263 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
            "Epoch 767/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8288 - val_loss: 0.3799 - val_accuracy: 0.8400\n",
            "Epoch 768/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8275 - val_loss: 0.3705 - val_accuracy: 0.8400\n",
            "Epoch 769/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8263 - val_loss: 0.3763 - val_accuracy: 0.8450\n",
            "Epoch 770/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8325 - val_loss: 0.3782 - val_accuracy: 0.8400\n",
            "Epoch 771/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8338 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
            "Epoch 772/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8338 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
            "Epoch 773/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3935 - accuracy: 0.8213 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
            "Epoch 774/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8300 - val_loss: 0.3724 - val_accuracy: 0.8400\n",
            "Epoch 775/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8325 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 776/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8225 - val_loss: 0.3745 - val_accuracy: 0.8400\n",
            "Epoch 777/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8288 - val_loss: 0.3724 - val_accuracy: 0.8450\n",
            "Epoch 778/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3894 - accuracy: 0.8338 - val_loss: 0.3766 - val_accuracy: 0.8400\n",
            "Epoch 779/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8250 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
            "Epoch 780/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8300 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
            "Epoch 781/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8275 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
            "Epoch 782/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3891 - accuracy: 0.8263 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
            "Epoch 783/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8300 - val_loss: 0.3681 - val_accuracy: 0.8450\n",
            "Epoch 784/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3711 - val_accuracy: 0.8400\n",
            "Epoch 785/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8263 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
            "Epoch 786/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8313 - val_loss: 0.3680 - val_accuracy: 0.8400\n",
            "Epoch 787/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8275 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 788/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8288 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 789/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8288 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 790/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8263 - val_loss: 0.3725 - val_accuracy: 0.8400\n",
            "Epoch 791/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8288 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
            "Epoch 792/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8313 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
            "Epoch 793/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8325 - val_loss: 0.3699 - val_accuracy: 0.8400\n",
            "Epoch 794/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8263 - val_loss: 0.3715 - val_accuracy: 0.8450\n",
            "Epoch 795/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8300 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
            "Epoch 796/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8288 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 797/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8263 - val_loss: 0.3680 - val_accuracy: 0.8400\n",
            "Epoch 798/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8238 - val_loss: 0.3798 - val_accuracy: 0.8450\n",
            "Epoch 799/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8313 - val_loss: 0.3731 - val_accuracy: 0.8450\n",
            "Epoch 800/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8288 - val_loss: 0.3712 - val_accuracy: 0.8400\n",
            "Epoch 801/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8313 - val_loss: 0.3688 - val_accuracy: 0.8450\n",
            "Epoch 802/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8250 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
            "Epoch 803/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8325 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
            "Epoch 804/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8275 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
            "Epoch 805/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8313 - val_loss: 0.3757 - val_accuracy: 0.8450\n",
            "Epoch 806/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8313 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 807/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8275 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
            "Epoch 808/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8300 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
            "Epoch 809/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8300 - val_loss: 0.3691 - val_accuracy: 0.8450\n",
            "Epoch 810/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8238 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
            "Epoch 811/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8288 - val_loss: 0.3696 - val_accuracy: 0.8450\n",
            "Epoch 812/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8288 - val_loss: 0.3719 - val_accuracy: 0.8450\n",
            "Epoch 813/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8288 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 814/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8288 - val_loss: 0.3670 - val_accuracy: 0.8400\n",
            "Epoch 815/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3659 - val_accuracy: 0.8400\n",
            "Epoch 816/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8238 - val_loss: 0.3727 - val_accuracy: 0.8450\n",
            "Epoch 817/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8250 - val_loss: 0.3719 - val_accuracy: 0.8450\n",
            "Epoch 818/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8313 - val_loss: 0.3804 - val_accuracy: 0.8400\n",
            "Epoch 819/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8288 - val_loss: 0.3634 - val_accuracy: 0.8400\n",
            "Epoch 820/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8250 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 821/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8250 - val_loss: 0.3734 - val_accuracy: 0.8400\n",
            "Epoch 822/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8300 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 823/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8250 - val_loss: 0.3732 - val_accuracy: 0.8400\n",
            "Epoch 824/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8300 - val_loss: 0.3684 - val_accuracy: 0.8400\n",
            "Epoch 825/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8325 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 826/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8325 - val_loss: 0.3753 - val_accuracy: 0.8400\n",
            "Epoch 827/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8300 - val_loss: 0.3692 - val_accuracy: 0.8450\n",
            "Epoch 828/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8250 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
            "Epoch 829/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8300 - val_loss: 0.3778 - val_accuracy: 0.8450\n",
            "Epoch 830/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8325 - val_loss: 0.3757 - val_accuracy: 0.8400\n",
            "Epoch 831/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8288 - val_loss: 0.3702 - val_accuracy: 0.8400\n",
            "Epoch 832/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8313 - val_loss: 0.3743 - val_accuracy: 0.8400\n",
            "Epoch 833/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8250 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 834/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8363 - val_loss: 0.3698 - val_accuracy: 0.8450\n",
            "Epoch 835/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8263 - val_loss: 0.3734 - val_accuracy: 0.8450\n",
            "Epoch 836/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8250 - val_loss: 0.3738 - val_accuracy: 0.8450\n",
            "Epoch 837/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8275 - val_loss: 0.3765 - val_accuracy: 0.8400\n",
            "Epoch 838/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8288 - val_loss: 0.3692 - val_accuracy: 0.8450\n",
            "Epoch 839/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8275 - val_loss: 0.3673 - val_accuracy: 0.8450\n",
            "Epoch 840/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8288 - val_loss: 0.3809 - val_accuracy: 0.8400\n",
            "Epoch 841/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8275 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
            "Epoch 842/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8288 - val_loss: 0.3697 - val_accuracy: 0.8400\n",
            "Epoch 843/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8350 - val_loss: 0.3697 - val_accuracy: 0.8400\n",
            "Epoch 844/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8300 - val_loss: 0.3736 - val_accuracy: 0.8400\n",
            "Epoch 845/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8263 - val_loss: 0.3711 - val_accuracy: 0.8400\n",
            "Epoch 846/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8313 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
            "Epoch 847/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8313 - val_loss: 0.3731 - val_accuracy: 0.8450\n",
            "Epoch 848/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8275 - val_loss: 0.3731 - val_accuracy: 0.8450\n",
            "Epoch 849/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8288 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 850/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8338 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 851/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8250 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
            "Epoch 852/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3805 - val_accuracy: 0.8400\n",
            "Epoch 853/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8325 - val_loss: 0.3694 - val_accuracy: 0.8400\n",
            "Epoch 854/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8300 - val_loss: 0.3720 - val_accuracy: 0.8400\n",
            "Epoch 855/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8275 - val_loss: 0.3688 - val_accuracy: 0.8400\n",
            "Epoch 856/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8350 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
            "Epoch 857/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8300 - val_loss: 0.3725 - val_accuracy: 0.8400\n",
            "Epoch 858/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3754 - val_accuracy: 0.8400\n",
            "Epoch 859/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8300 - val_loss: 0.3671 - val_accuracy: 0.8450\n",
            "Epoch 860/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8300 - val_loss: 0.3723 - val_accuracy: 0.8400\n",
            "Epoch 861/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8338 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
            "Epoch 862/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8288 - val_loss: 0.3684 - val_accuracy: 0.8450\n",
            "Epoch 863/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8275 - val_loss: 0.3748 - val_accuracy: 0.8400\n",
            "Epoch 864/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8300 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
            "Epoch 865/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8313 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 866/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8250 - val_loss: 0.3713 - val_accuracy: 0.8450\n",
            "Epoch 867/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.8325 - val_loss: 0.3780 - val_accuracy: 0.8400\n",
            "Epoch 868/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8338 - val_loss: 0.3731 - val_accuracy: 0.8450\n",
            "Epoch 869/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8325 - val_loss: 0.3773 - val_accuracy: 0.8400\n",
            "Epoch 870/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8300 - val_loss: 0.3711 - val_accuracy: 0.8450\n",
            "Epoch 871/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3902 - accuracy: 0.8300 - val_loss: 0.3715 - val_accuracy: 0.8400\n",
            "Epoch 872/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8288 - val_loss: 0.3765 - val_accuracy: 0.8400\n",
            "Epoch 873/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8350 - val_loss: 0.3732 - val_accuracy: 0.8450\n",
            "Epoch 874/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8338 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
            "Epoch 875/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8338 - val_loss: 0.3701 - val_accuracy: 0.8450\n",
            "Epoch 876/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8275 - val_loss: 0.3708 - val_accuracy: 0.8400\n",
            "Epoch 877/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8288 - val_loss: 0.3736 - val_accuracy: 0.8450\n",
            "Epoch 878/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8350 - val_loss: 0.3745 - val_accuracy: 0.8450\n",
            "Epoch 879/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8275 - val_loss: 0.3746 - val_accuracy: 0.8350\n",
            "Epoch 880/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8300 - val_loss: 0.3834 - val_accuracy: 0.8450\n",
            "Epoch 881/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8363 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
            "Epoch 882/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8288 - val_loss: 0.3739 - val_accuracy: 0.8350\n",
            "Epoch 883/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8338 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 884/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8325 - val_loss: 0.3739 - val_accuracy: 0.8450\n",
            "Epoch 885/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8288 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 886/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8288 - val_loss: 0.3834 - val_accuracy: 0.8450\n",
            "Epoch 887/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8313 - val_loss: 0.3760 - val_accuracy: 0.8350\n",
            "Epoch 888/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8263 - val_loss: 0.3756 - val_accuracy: 0.8350\n",
            "Epoch 889/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8275 - val_loss: 0.3743 - val_accuracy: 0.8400\n",
            "Epoch 890/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8300 - val_loss: 0.3744 - val_accuracy: 0.8400\n",
            "Epoch 891/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8313 - val_loss: 0.3815 - val_accuracy: 0.8350\n",
            "Epoch 892/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3681 - val_accuracy: 0.8450\n",
            "Epoch 893/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8375 - val_loss: 0.3689 - val_accuracy: 0.8400\n",
            "Epoch 894/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8300 - val_loss: 0.3664 - val_accuracy: 0.8350\n",
            "Epoch 895/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8288 - val_loss: 0.3814 - val_accuracy: 0.8450\n",
            "Epoch 896/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8300 - val_loss: 0.3656 - val_accuracy: 0.8450\n",
            "Epoch 897/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8338 - val_loss: 0.3788 - val_accuracy: 0.8400\n",
            "Epoch 898/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8275 - val_loss: 0.3691 - val_accuracy: 0.8350\n",
            "Epoch 899/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8300 - val_loss: 0.3725 - val_accuracy: 0.8400\n",
            "Epoch 900/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8238 - val_loss: 0.3659 - val_accuracy: 0.8350\n",
            "Epoch 901/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8350 - val_loss: 0.3729 - val_accuracy: 0.8400\n",
            "Epoch 902/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8288 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
            "Epoch 903/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8238 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
            "Epoch 904/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8388 - val_loss: 0.3798 - val_accuracy: 0.8450\n",
            "Epoch 905/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8313 - val_loss: 0.3670 - val_accuracy: 0.8450\n",
            "Epoch 906/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8300 - val_loss: 0.3784 - val_accuracy: 0.8400\n",
            "Epoch 907/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8300 - val_loss: 0.3751 - val_accuracy: 0.8400\n",
            "Epoch 908/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8300 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 909/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8263 - val_loss: 0.3717 - val_accuracy: 0.8350\n",
            "Epoch 910/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8338 - val_loss: 0.3769 - val_accuracy: 0.8350\n",
            "Epoch 911/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8363 - val_loss: 0.3706 - val_accuracy: 0.8400\n",
            "Epoch 912/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8275 - val_loss: 0.3785 - val_accuracy: 0.8350\n",
            "Epoch 913/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8338 - val_loss: 0.3745 - val_accuracy: 0.8450\n",
            "Epoch 914/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8263 - val_loss: 0.3708 - val_accuracy: 0.8450\n",
            "Epoch 915/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8350 - val_loss: 0.3776 - val_accuracy: 0.8350\n",
            "Epoch 916/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8350 - val_loss: 0.3702 - val_accuracy: 0.8450\n",
            "Epoch 917/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8300 - val_loss: 0.3706 - val_accuracy: 0.8350\n",
            "Epoch 918/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8275 - val_loss: 0.3735 - val_accuracy: 0.8400\n",
            "Epoch 919/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8300 - val_loss: 0.3655 - val_accuracy: 0.8350\n",
            "Epoch 920/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8288 - val_loss: 0.3742 - val_accuracy: 0.8400\n",
            "Epoch 921/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8313 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 922/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8275 - val_loss: 0.3712 - val_accuracy: 0.8350\n",
            "Epoch 923/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8288 - val_loss: 0.3697 - val_accuracy: 0.8350\n",
            "Epoch 924/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8275 - val_loss: 0.3756 - val_accuracy: 0.8450\n",
            "Epoch 925/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8300 - val_loss: 0.3707 - val_accuracy: 0.8350\n",
            "Epoch 926/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8275 - val_loss: 0.3754 - val_accuracy: 0.8400\n",
            "Epoch 927/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8313 - val_loss: 0.3709 - val_accuracy: 0.8350\n",
            "Epoch 928/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8288 - val_loss: 0.3777 - val_accuracy: 0.8350\n",
            "Epoch 929/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8338 - val_loss: 0.3704 - val_accuracy: 0.8350\n",
            "Epoch 930/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8263 - val_loss: 0.3752 - val_accuracy: 0.8400\n",
            "Epoch 931/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8313 - val_loss: 0.3688 - val_accuracy: 0.8350\n",
            "Epoch 932/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8275 - val_loss: 0.3691 - val_accuracy: 0.8400\n",
            "Epoch 933/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8275 - val_loss: 0.3846 - val_accuracy: 0.8400\n",
            "Epoch 934/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8313 - val_loss: 0.3638 - val_accuracy: 0.8350\n",
            "Epoch 935/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8313 - val_loss: 0.3763 - val_accuracy: 0.8350\n",
            "Epoch 936/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8288 - val_loss: 0.3690 - val_accuracy: 0.8350\n",
            "Epoch 937/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8325 - val_loss: 0.3690 - val_accuracy: 0.8350\n",
            "Epoch 938/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8288 - val_loss: 0.3793 - val_accuracy: 0.8400\n",
            "Epoch 939/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8338 - val_loss: 0.3752 - val_accuracy: 0.8350\n",
            "Epoch 940/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8238 - val_loss: 0.3699 - val_accuracy: 0.8350\n",
            "Epoch 941/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8300 - val_loss: 0.3752 - val_accuracy: 0.8350\n",
            "Epoch 942/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8363 - val_loss: 0.3726 - val_accuracy: 0.8350\n",
            "Epoch 943/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8275 - val_loss: 0.3783 - val_accuracy: 0.8450\n",
            "Epoch 944/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8300 - val_loss: 0.3689 - val_accuracy: 0.8350\n",
            "Epoch 945/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8250 - val_loss: 0.3788 - val_accuracy: 0.8350\n",
            "Epoch 946/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8275 - val_loss: 0.3743 - val_accuracy: 0.8350\n",
            "Epoch 947/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8338 - val_loss: 0.3773 - val_accuracy: 0.8350\n",
            "Epoch 948/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8300 - val_loss: 0.3700 - val_accuracy: 0.8350\n",
            "Epoch 949/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8338 - val_loss: 0.3830 - val_accuracy: 0.8400\n",
            "Epoch 950/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8300 - val_loss: 0.3714 - val_accuracy: 0.8350\n",
            "Epoch 951/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8275 - val_loss: 0.3738 - val_accuracy: 0.8350\n",
            "Epoch 952/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8288 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 953/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8288 - val_loss: 0.3765 - val_accuracy: 0.8350\n",
            "Epoch 954/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8300 - val_loss: 0.3742 - val_accuracy: 0.8350\n",
            "Epoch 955/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3909 - accuracy: 0.8300 - val_loss: 0.3663 - val_accuracy: 0.8350\n",
            "Epoch 956/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3902 - accuracy: 0.8263 - val_loss: 0.3758 - val_accuracy: 0.8350\n",
            "Epoch 957/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8363 - val_loss: 0.3777 - val_accuracy: 0.8350\n",
            "Epoch 958/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3883 - accuracy: 0.8300 - val_loss: 0.3758 - val_accuracy: 0.8400\n",
            "Epoch 959/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8350 - val_loss: 0.3787 - val_accuracy: 0.8400\n",
            "Epoch 960/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8325 - val_loss: 0.3753 - val_accuracy: 0.8350\n",
            "Epoch 961/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8300 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
            "Epoch 962/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8300 - val_loss: 0.3696 - val_accuracy: 0.8350\n",
            "Epoch 963/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8263 - val_loss: 0.3747 - val_accuracy: 0.8350\n",
            "Epoch 964/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8325 - val_loss: 0.3685 - val_accuracy: 0.8350\n",
            "Epoch 965/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8250 - val_loss: 0.3733 - val_accuracy: 0.8350\n",
            "Epoch 966/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8288 - val_loss: 0.3751 - val_accuracy: 0.8350\n",
            "Epoch 967/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3877 - accuracy: 0.8325 - val_loss: 0.3783 - val_accuracy: 0.8400\n",
            "Epoch 968/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8300 - val_loss: 0.3726 - val_accuracy: 0.8350\n",
            "Epoch 969/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3892 - accuracy: 0.8300 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 970/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8288 - val_loss: 0.3747 - val_accuracy: 0.8400\n",
            "Epoch 971/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3877 - accuracy: 0.8300 - val_loss: 0.3701 - val_accuracy: 0.8400\n",
            "Epoch 972/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8288 - val_loss: 0.3759 - val_accuracy: 0.8350\n",
            "Epoch 973/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3883 - accuracy: 0.8288 - val_loss: 0.3756 - val_accuracy: 0.8350\n",
            "Epoch 974/1000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8388 - val_loss: 0.3782 - val_accuracy: 0.8350\n",
            "Epoch 975/1000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3866 - accuracy: 0.8300 - val_loss: 0.3714 - val_accuracy: 0.8350\n",
            "Epoch 976/1000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8300 - val_loss: 0.3744 - val_accuracy: 0.8350\n",
            "Epoch 977/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8338 - val_loss: 0.3770 - val_accuracy: 0.8350\n",
            "Epoch 978/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8288 - val_loss: 0.3738 - val_accuracy: 0.8350\n",
            "Epoch 979/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8313 - val_loss: 0.3789 - val_accuracy: 0.8350\n",
            "Epoch 980/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8313 - val_loss: 0.3726 - val_accuracy: 0.8350\n",
            "Epoch 981/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8325 - val_loss: 0.3731 - val_accuracy: 0.8350\n",
            "Epoch 982/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8288 - val_loss: 0.3717 - val_accuracy: 0.8350\n",
            "Epoch 983/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8325 - val_loss: 0.3775 - val_accuracy: 0.8350\n",
            "Epoch 984/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8263 - val_loss: 0.3734 - val_accuracy: 0.8350\n",
            "Epoch 985/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8325 - val_loss: 0.3708 - val_accuracy: 0.8350\n",
            "Epoch 986/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8288 - val_loss: 0.3740 - val_accuracy: 0.8350\n",
            "Epoch 987/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8325 - val_loss: 0.3763 - val_accuracy: 0.8350\n",
            "Epoch 988/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8288 - val_loss: 0.3783 - val_accuracy: 0.8400\n",
            "Epoch 989/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8325 - val_loss: 0.3668 - val_accuracy: 0.8350\n",
            "Epoch 990/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8300 - val_loss: 0.3740 - val_accuracy: 0.8350\n",
            "Epoch 991/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8250 - val_loss: 0.3764 - val_accuracy: 0.8350\n",
            "Epoch 992/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8388 - val_loss: 0.3780 - val_accuracy: 0.8400\n",
            "Epoch 993/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8250 - val_loss: 0.3762 - val_accuracy: 0.8350\n",
            "Epoch 994/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8375 - val_loss: 0.3738 - val_accuracy: 0.8350\n",
            "Epoch 995/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8288 - val_loss: 0.3748 - val_accuracy: 0.8350\n",
            "Epoch 996/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8338 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 997/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8313 - val_loss: 0.3726 - val_accuracy: 0.8350\n",
            "Epoch 998/1000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8300 - val_loss: 0.3746 - val_accuracy: 0.8350\n",
            "Epoch 999/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8363 - val_loss: 0.3727 - val_accuracy: 0.8350\n",
            "Epoch 1000/1000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8300 - val_loss: 0.3797 - val_accuracy: 0.8350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 성능 평가하기\n",
        "_, train_acc = model.evaluate(train_X, train_y)\n",
        "_, test_acc = model.evaluate(test_X, test_y)\n",
        "print('Train: %.3f, Test: %.3f' %(train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL0jVTtJMg8F",
        "outputId": "9d2e98ed-e59e-4e4a-9b4d-f37c8a5db244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8350\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8350\n",
            "Train: 0.835, Test: 0.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도를 기준으로 모델의 학습 곡선 그리기\n",
        "plt.plot(hist.history['accuracy'], label='train')\n",
        "plt.plot(hist.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "owUP7Ea1NOh7",
        "outputId": "ad72ca4a-1d55-40d7-e7eb-40a96f591ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# L2규제화\n",
        "model.add(Dense(units=16, kernel_regularizer=regularizers.l2(lambda), acitivation='relu')\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IeBZaIcYVwFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# 이미지 강화\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "datagen.fit(training_set)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bHqh-HPwWUs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 신경망에 배치 정규화층 추가하기"
      ],
      "metadata": {
        "id": "P30H70N5c2tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(hidden_units, activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units, activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HCB7dmc9dmSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 분류 정확도 개선하기"
      ],
      "metadata": {
        "id": "GnD-zwANeUCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터 준비"
      ],
      "metadata": {
        "id": "5dShMQvJfGWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "(X_train, X_valid) = X_train[5000:], X_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71UrvwXHDHyP",
        "outputId": "c5e951bb-c184-4459-e76b-2212ee2e496e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모양 확인하기\n",
        "print('X_train = ', X_train.shape)\n",
        "print('X_valid = ', X_valid.shape)\n",
        "print('X_test = ', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0POYgWsfrBW",
        "outputId": "c2a650e4-19ca-4182-f670-8db39633b5ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train =  (45000, 32, 32, 3)\n",
            "X_valid =  (5000, 32, 32, 3)\n",
            "X_test =  (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "std = np.std(X_train, axis=(0,1,2,3))\n",
        "X_train = (X_train - mean) / (std + 1e-7)\n",
        "X_valid = (X_valid - mean) / (std + 1e-7)\n",
        "X_test = (X_test - mean) / (std + 1e-7)"
      ],
      "metadata": {
        "id": "KEvC5WH8f8m_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩 적용하기\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_valid = to_categorical(y_valid, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "URLHAraKgn3t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 강화하기\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "## 훈련 데이터를 대상으로 변환된 데이터 생성하기\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "3B12cq75g3Zy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 모델 구조 정의"
      ],
      "metadata": {
        "id": "mbQ1D4zFuEM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_hidden_units = 32 # 은닉층의 유닛 수 정의\n",
        "weight_decay = 1e-4    # L2 규제화 파라미터 lambda\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "model.add(Conv2D(base_hidden_units,kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                 input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(base_hidden_units*2, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(base_hidden_units*2, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(base_hidden_units*4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(base_hidden_units*4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHAnVCl7uDw9",
        "outputId": "003729d3-c516-4d57-be23-950cdd43f2d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309290 (1.18 MB)\n",
            "Trainable params: 308394 (1.18 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 모델 학습하기"
      ],
      "metadata": {
        "id": "MZ_lnLWQx6H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 125\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.100epochs.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "# 초기 학습률과 지수적 감소를 위한 설정\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# optimizer = keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "optimizer = Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n",
        "                           steps_per_epoch=X_train.shape[0]//batch_size, epochs=epochs,\n",
        "                           verbose=2, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCa2eYihx5Xe",
        "outputId": "bf9fc8de-9c67-4e2c-a20e-6b80d9ff7443"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-33cad72f9d68>:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.00335, saving model to model.100epochs.hdf5\n",
            "351/351 - 36s - loss: 2.8670 - accuracy: 0.2617 - val_loss: 2.0034 - val_accuracy: 0.2962 - 36s/epoch - 102ms/step\n",
            "Epoch 2/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 2.00335 to 1.49578, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 2.1384 - accuracy: 0.3513 - val_loss: 1.4958 - val_accuracy: 0.4914 - 26s/epoch - 73ms/step\n",
            "Epoch 3/125\n",
            "\n",
            "Epoch 3: val_loss improved from 1.49578 to 1.45193, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.9029 - accuracy: 0.4007 - val_loss: 1.4519 - val_accuracy: 0.4962 - 26s/epoch - 73ms/step\n",
            "Epoch 4/125\n",
            "\n",
            "Epoch 4: val_loss improved from 1.45193 to 1.41017, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.7497 - accuracy: 0.4364 - val_loss: 1.4102 - val_accuracy: 0.5042 - 26s/epoch - 73ms/step\n",
            "Epoch 5/125\n",
            "\n",
            "Epoch 5: val_loss improved from 1.41017 to 1.37609, saving model to model.100epochs.hdf5\n",
            "351/351 - 27s - loss: 1.6293 - accuracy: 0.4669 - val_loss: 1.3761 - val_accuracy: 0.5174 - 27s/epoch - 76ms/step\n",
            "Epoch 6/125\n",
            "\n",
            "Epoch 6: val_loss improved from 1.37609 to 1.33284, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 1.5465 - accuracy: 0.4939 - val_loss: 1.3328 - val_accuracy: 0.5452 - 25s/epoch - 71ms/step\n",
            "Epoch 7/125\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.33284\n",
            "351/351 - 25s - loss: 1.4890 - accuracy: 0.5094 - val_loss: 1.3486 - val_accuracy: 0.5394 - 25s/epoch - 72ms/step\n",
            "Epoch 8/125\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.33284\n",
            "351/351 - 25s - loss: 1.4146 - accuracy: 0.5347 - val_loss: 1.3520 - val_accuracy: 0.5426 - 25s/epoch - 72ms/step\n",
            "Epoch 9/125\n",
            "\n",
            "Epoch 9: val_loss improved from 1.33284 to 1.25136, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 1.3587 - accuracy: 0.5510 - val_loss: 1.2514 - val_accuracy: 0.5750 - 25s/epoch - 73ms/step\n",
            "Epoch 10/125\n",
            "\n",
            "Epoch 10: val_loss improved from 1.25136 to 1.19187, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.3018 - accuracy: 0.5714 - val_loss: 1.1919 - val_accuracy: 0.6022 - 26s/epoch - 73ms/step\n",
            "Epoch 11/125\n",
            "\n",
            "Epoch 11: val_loss improved from 1.19187 to 1.17633, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.2624 - accuracy: 0.5823 - val_loss: 1.1763 - val_accuracy: 0.6020 - 26s/epoch - 74ms/step\n",
            "Epoch 12/125\n",
            "\n",
            "Epoch 12: val_loss improved from 1.17633 to 1.17596, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 1.2246 - accuracy: 0.5960 - val_loss: 1.1760 - val_accuracy: 0.6046 - 25s/epoch - 73ms/step\n",
            "Epoch 13/125\n",
            "\n",
            "Epoch 13: val_loss improved from 1.17596 to 1.03926, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.1847 - accuracy: 0.6076 - val_loss: 1.0393 - val_accuracy: 0.6506 - 26s/epoch - 73ms/step\n",
            "Epoch 14/125\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.03926\n",
            "351/351 - 25s - loss: 1.1498 - accuracy: 0.6169 - val_loss: 1.0766 - val_accuracy: 0.6386 - 25s/epoch - 72ms/step\n",
            "Epoch 15/125\n",
            "\n",
            "Epoch 15: val_loss did not improve from 1.03926\n",
            "351/351 - 25s - loss: 1.1189 - accuracy: 0.6287 - val_loss: 1.0626 - val_accuracy: 0.6464 - 25s/epoch - 72ms/step\n",
            "Epoch 16/125\n",
            "\n",
            "Epoch 16: val_loss improved from 1.03926 to 1.00724, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 1.0899 - accuracy: 0.6372 - val_loss: 1.0072 - val_accuracy: 0.6672 - 25s/epoch - 72ms/step\n",
            "Epoch 17/125\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.00724\n",
            "351/351 - 25s - loss: 1.0634 - accuracy: 0.6460 - val_loss: 1.0246 - val_accuracy: 0.6584 - 25s/epoch - 72ms/step\n",
            "Epoch 18/125\n",
            "\n",
            "Epoch 18: val_loss improved from 1.00724 to 1.00287, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 1.0427 - accuracy: 0.6521 - val_loss: 1.0029 - val_accuracy: 0.6700 - 25s/epoch - 72ms/step\n",
            "Epoch 19/125\n",
            "\n",
            "Epoch 19: val_loss improved from 1.00287 to 0.93115, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 1.0036 - accuracy: 0.6668 - val_loss: 0.9312 - val_accuracy: 0.6932 - 26s/epoch - 73ms/step\n",
            "Epoch 20/125\n",
            "\n",
            "Epoch 20: val_loss improved from 0.93115 to 0.91465, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.9892 - accuracy: 0.6706 - val_loss: 0.9146 - val_accuracy: 0.7010 - 25s/epoch - 73ms/step\n",
            "Epoch 21/125\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.91465\n",
            "351/351 - 26s - loss: 0.9752 - accuracy: 0.6754 - val_loss: 0.9330 - val_accuracy: 0.6962 - 26s/epoch - 73ms/step\n",
            "Epoch 22/125\n",
            "\n",
            "Epoch 22: val_loss improved from 0.91465 to 0.88530, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.9542 - accuracy: 0.6834 - val_loss: 0.8853 - val_accuracy: 0.7058 - 26s/epoch - 73ms/step\n",
            "Epoch 23/125\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.88530\n",
            "351/351 - 27s - loss: 0.9370 - accuracy: 0.6898 - val_loss: 0.8889 - val_accuracy: 0.7074 - 27s/epoch - 76ms/step\n",
            "Epoch 24/125\n",
            "\n",
            "Epoch 24: val_loss improved from 0.88530 to 0.84563, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.9214 - accuracy: 0.6925 - val_loss: 0.8456 - val_accuracy: 0.7250 - 25s/epoch - 73ms/step\n",
            "Epoch 25/125\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.84563\n",
            "351/351 - 26s - loss: 0.9061 - accuracy: 0.7000 - val_loss: 0.9197 - val_accuracy: 0.7052 - 26s/epoch - 73ms/step\n",
            "Epoch 26/125\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.84563\n",
            "351/351 - 26s - loss: 0.8897 - accuracy: 0.7057 - val_loss: 0.8758 - val_accuracy: 0.7192 - 26s/epoch - 73ms/step\n",
            "Epoch 27/125\n",
            "\n",
            "Epoch 27: val_loss improved from 0.84563 to 0.82539, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.8720 - accuracy: 0.7089 - val_loss: 0.8254 - val_accuracy: 0.7308 - 26s/epoch - 73ms/step\n",
            "Epoch 28/125\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.82539\n",
            "351/351 - 25s - loss: 0.8559 - accuracy: 0.7145 - val_loss: 0.8284 - val_accuracy: 0.7316 - 25s/epoch - 73ms/step\n",
            "Epoch 29/125\n",
            "\n",
            "Epoch 29: val_loss improved from 0.82539 to 0.79382, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.8414 - accuracy: 0.7197 - val_loss: 0.7938 - val_accuracy: 0.7420 - 26s/epoch - 73ms/step\n",
            "Epoch 30/125\n",
            "\n",
            "Epoch 30: val_loss improved from 0.79382 to 0.78488, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.8365 - accuracy: 0.7228 - val_loss: 0.7849 - val_accuracy: 0.7554 - 25s/epoch - 72ms/step\n",
            "Epoch 31/125\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.78488\n",
            "351/351 - 26s - loss: 0.8185 - accuracy: 0.7240 - val_loss: 0.8174 - val_accuracy: 0.7414 - 26s/epoch - 73ms/step\n",
            "Epoch 32/125\n",
            "\n",
            "Epoch 32: val_loss improved from 0.78488 to 0.76973, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.8060 - accuracy: 0.7314 - val_loss: 0.7697 - val_accuracy: 0.7560 - 25s/epoch - 72ms/step\n",
            "Epoch 33/125\n",
            "\n",
            "Epoch 33: val_loss improved from 0.76973 to 0.76505, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7997 - accuracy: 0.7344 - val_loss: 0.7651 - val_accuracy: 0.7558 - 25s/epoch - 72ms/step\n",
            "Epoch 34/125\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.76505\n",
            "351/351 - 25s - loss: 0.7913 - accuracy: 0.7373 - val_loss: 0.8034 - val_accuracy: 0.7436 - 25s/epoch - 72ms/step\n",
            "Epoch 35/125\n",
            "\n",
            "Epoch 35: val_loss improved from 0.76505 to 0.76141, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7736 - accuracy: 0.7430 - val_loss: 0.7614 - val_accuracy: 0.7606 - 25s/epoch - 72ms/step\n",
            "Epoch 36/125\n",
            "\n",
            "Epoch 36: val_loss improved from 0.76141 to 0.71751, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7628 - accuracy: 0.7489 - val_loss: 0.7175 - val_accuracy: 0.7716 - 25s/epoch - 73ms/step\n",
            "Epoch 37/125\n",
            "\n",
            "Epoch 37: val_loss improved from 0.71751 to 0.71382, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7552 - accuracy: 0.7484 - val_loss: 0.7138 - val_accuracy: 0.7726 - 25s/epoch - 72ms/step\n",
            "Epoch 38/125\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.71382\n",
            "351/351 - 25s - loss: 0.7496 - accuracy: 0.7532 - val_loss: 0.7479 - val_accuracy: 0.7598 - 25s/epoch - 72ms/step\n",
            "Epoch 39/125\n",
            "\n",
            "Epoch 39: val_loss improved from 0.71382 to 0.70346, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7388 - accuracy: 0.7535 - val_loss: 0.7035 - val_accuracy: 0.7738 - 25s/epoch - 73ms/step\n",
            "Epoch 40/125\n",
            "\n",
            "Epoch 40: val_loss improved from 0.70346 to 0.67280, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7307 - accuracy: 0.7586 - val_loss: 0.6728 - val_accuracy: 0.7872 - 25s/epoch - 72ms/step\n",
            "Epoch 41/125\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.67280\n",
            "351/351 - 26s - loss: 0.7200 - accuracy: 0.7620 - val_loss: 0.6924 - val_accuracy: 0.7800 - 26s/epoch - 73ms/step\n",
            "Epoch 42/125\n",
            "\n",
            "Epoch 42: val_loss improved from 0.67280 to 0.66818, saving model to model.100epochs.hdf5\n",
            "351/351 - 27s - loss: 0.7141 - accuracy: 0.7618 - val_loss: 0.6682 - val_accuracy: 0.7878 - 27s/epoch - 76ms/step\n",
            "Epoch 43/125\n",
            "\n",
            "Epoch 43: val_loss improved from 0.66818 to 0.66123, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.7088 - accuracy: 0.7647 - val_loss: 0.6612 - val_accuracy: 0.7948 - 25s/epoch - 73ms/step\n",
            "Epoch 44/125\n",
            "\n",
            "Epoch 44: val_loss improved from 0.66123 to 0.62310, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.6986 - accuracy: 0.7667 - val_loss: 0.6231 - val_accuracy: 0.8030 - 25s/epoch - 72ms/step\n",
            "Epoch 45/125\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.62310\n",
            "351/351 - 26s - loss: 0.6944 - accuracy: 0.7697 - val_loss: 0.6620 - val_accuracy: 0.7954 - 26s/epoch - 74ms/step\n",
            "Epoch 46/125\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.62310\n",
            "351/351 - 26s - loss: 0.6806 - accuracy: 0.7751 - val_loss: 0.6739 - val_accuracy: 0.7898 - 26s/epoch - 73ms/step\n",
            "Epoch 47/125\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.62310\n",
            "351/351 - 25s - loss: 0.6798 - accuracy: 0.7759 - val_loss: 0.6427 - val_accuracy: 0.8014 - 25s/epoch - 72ms/step\n",
            "Epoch 48/125\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.62310\n",
            "351/351 - 25s - loss: 0.6754 - accuracy: 0.7768 - val_loss: 0.6648 - val_accuracy: 0.7910 - 25s/epoch - 72ms/step\n",
            "Epoch 49/125\n",
            "\n",
            "Epoch 49: val_loss improved from 0.62310 to 0.61785, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.6642 - accuracy: 0.7795 - val_loss: 0.6178 - val_accuracy: 0.8046 - 26s/epoch - 73ms/step\n",
            "Epoch 50/125\n",
            "\n",
            "Epoch 50: val_loss improved from 0.61785 to 0.61695, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.6581 - accuracy: 0.7820 - val_loss: 0.6170 - val_accuracy: 0.8062 - 25s/epoch - 73ms/step\n",
            "Epoch 51/125\n",
            "\n",
            "Epoch 51: val_loss improved from 0.61695 to 0.60352, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.6558 - accuracy: 0.7835 - val_loss: 0.6035 - val_accuracy: 0.8076 - 26s/epoch - 74ms/step\n",
            "Epoch 52/125\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.60352\n",
            "351/351 - 25s - loss: 0.6465 - accuracy: 0.7868 - val_loss: 0.6267 - val_accuracy: 0.8014 - 25s/epoch - 72ms/step\n",
            "Epoch 53/125\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.60352\n",
            "351/351 - 25s - loss: 0.6423 - accuracy: 0.7900 - val_loss: 0.6351 - val_accuracy: 0.8044 - 25s/epoch - 73ms/step\n",
            "Epoch 54/125\n",
            "\n",
            "Epoch 54: val_loss improved from 0.60352 to 0.58156, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.6416 - accuracy: 0.7875 - val_loss: 0.5816 - val_accuracy: 0.8168 - 25s/epoch - 72ms/step\n",
            "Epoch 55/125\n",
            "\n",
            "Epoch 55: val_loss improved from 0.58156 to 0.56655, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.6344 - accuracy: 0.7903 - val_loss: 0.5665 - val_accuracy: 0.8248 - 25s/epoch - 72ms/step\n",
            "Epoch 56/125\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.56655\n",
            "351/351 - 25s - loss: 0.6306 - accuracy: 0.7916 - val_loss: 0.6111 - val_accuracy: 0.8106 - 25s/epoch - 72ms/step\n",
            "Epoch 57/125\n",
            "\n",
            "Epoch 57: val_loss improved from 0.56655 to 0.56196, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.6236 - accuracy: 0.7951 - val_loss: 0.5620 - val_accuracy: 0.8272 - 25s/epoch - 72ms/step\n",
            "Epoch 58/125\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.56196\n",
            "351/351 - 28s - loss: 0.6225 - accuracy: 0.7968 - val_loss: 0.5700 - val_accuracy: 0.8212 - 28s/epoch - 80ms/step\n",
            "Epoch 59/125\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.56196\n",
            "351/351 - 27s - loss: 0.6108 - accuracy: 0.8000 - val_loss: 0.5850 - val_accuracy: 0.8146 - 27s/epoch - 76ms/step\n",
            "Epoch 60/125\n",
            "\n",
            "Epoch 60: val_loss improved from 0.56196 to 0.54408, saving model to model.100epochs.hdf5\n",
            "351/351 - 27s - loss: 0.6080 - accuracy: 0.7993 - val_loss: 0.5441 - val_accuracy: 0.8296 - 27s/epoch - 76ms/step\n",
            "Epoch 61/125\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.54408\n",
            "351/351 - 26s - loss: 0.6012 - accuracy: 0.8013 - val_loss: 0.5728 - val_accuracy: 0.8220 - 26s/epoch - 75ms/step\n",
            "Epoch 62/125\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.54408\n",
            "351/351 - 28s - loss: 0.6049 - accuracy: 0.8028 - val_loss: 0.5594 - val_accuracy: 0.8256 - 28s/epoch - 80ms/step\n",
            "Epoch 63/125\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.54408\n",
            "351/351 - 27s - loss: 0.6056 - accuracy: 0.8018 - val_loss: 0.5611 - val_accuracy: 0.8240 - 27s/epoch - 77ms/step\n",
            "Epoch 64/125\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.54408\n",
            "351/351 - 26s - loss: 0.5956 - accuracy: 0.8048 - val_loss: 0.5448 - val_accuracy: 0.8350 - 26s/epoch - 75ms/step\n",
            "Epoch 65/125\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.54408\n",
            "351/351 - 26s - loss: 0.5829 - accuracy: 0.8083 - val_loss: 0.5497 - val_accuracy: 0.8334 - 26s/epoch - 75ms/step\n",
            "Epoch 66/125\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.54408\n",
            "351/351 - 26s - loss: 0.5836 - accuracy: 0.8086 - val_loss: 0.5490 - val_accuracy: 0.8298 - 26s/epoch - 75ms/step\n",
            "Epoch 67/125\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.54408\n",
            "351/351 - 26s - loss: 0.5850 - accuracy: 0.8086 - val_loss: 0.5628 - val_accuracy: 0.8236 - 26s/epoch - 75ms/step\n",
            "Epoch 68/125\n",
            "\n",
            "Epoch 68: val_loss improved from 0.54408 to 0.52403, saving model to model.100epochs.hdf5\n",
            "351/351 - 27s - loss: 0.5813 - accuracy: 0.8098 - val_loss: 0.5240 - val_accuracy: 0.8386 - 27s/epoch - 76ms/step\n",
            "Epoch 69/125\n",
            "\n",
            "Epoch 69: val_loss improved from 0.52403 to 0.52169, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.5675 - accuracy: 0.8145 - val_loss: 0.5217 - val_accuracy: 0.8378 - 26s/epoch - 74ms/step\n",
            "Epoch 70/125\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.52169\n",
            "351/351 - 27s - loss: 0.5643 - accuracy: 0.8155 - val_loss: 0.5476 - val_accuracy: 0.8302 - 27s/epoch - 77ms/step\n",
            "Epoch 71/125\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.52169\n",
            "351/351 - 27s - loss: 0.5626 - accuracy: 0.8143 - val_loss: 0.5345 - val_accuracy: 0.8334 - 27s/epoch - 77ms/step\n",
            "Epoch 72/125\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.52169\n",
            "351/351 - 27s - loss: 0.5629 - accuracy: 0.8149 - val_loss: 0.5652 - val_accuracy: 0.8240 - 27s/epoch - 78ms/step\n",
            "Epoch 73/125\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.52169\n",
            "351/351 - 26s - loss: 0.5577 - accuracy: 0.8186 - val_loss: 0.5279 - val_accuracy: 0.8384 - 26s/epoch - 75ms/step\n",
            "Epoch 74/125\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.52169\n",
            "351/351 - 26s - loss: 0.5522 - accuracy: 0.8188 - val_loss: 0.5357 - val_accuracy: 0.8342 - 26s/epoch - 73ms/step\n",
            "Epoch 75/125\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.52169\n",
            "351/351 - 27s - loss: 0.5536 - accuracy: 0.8205 - val_loss: 0.5396 - val_accuracy: 0.8314 - 27s/epoch - 76ms/step\n",
            "Epoch 76/125\n",
            "\n",
            "Epoch 76: val_loss improved from 0.52169 to 0.51073, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5483 - accuracy: 0.8200 - val_loss: 0.5107 - val_accuracy: 0.8400 - 25s/epoch - 73ms/step\n",
            "Epoch 77/125\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.51073\n",
            "351/351 - 25s - loss: 0.5438 - accuracy: 0.8229 - val_loss: 0.5320 - val_accuracy: 0.8302 - 25s/epoch - 73ms/step\n",
            "Epoch 78/125\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.51073\n",
            "351/351 - 25s - loss: 0.5392 - accuracy: 0.8234 - val_loss: 0.5380 - val_accuracy: 0.8360 - 25s/epoch - 72ms/step\n",
            "Epoch 79/125\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.51073\n",
            "351/351 - 25s - loss: 0.5313 - accuracy: 0.8258 - val_loss: 0.5422 - val_accuracy: 0.8374 - 25s/epoch - 72ms/step\n",
            "Epoch 80/125\n",
            "\n",
            "Epoch 80: val_loss improved from 0.51073 to 0.50404, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5368 - accuracy: 0.8247 - val_loss: 0.5040 - val_accuracy: 0.8440 - 25s/epoch - 71ms/step\n",
            "Epoch 81/125\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.50404\n",
            "351/351 - 27s - loss: 0.5346 - accuracy: 0.8266 - val_loss: 0.5138 - val_accuracy: 0.8438 - 27s/epoch - 77ms/step\n",
            "Epoch 82/125\n",
            "\n",
            "Epoch 82: val_loss improved from 0.50404 to 0.50349, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5325 - accuracy: 0.8259 - val_loss: 0.5035 - val_accuracy: 0.8442 - 25s/epoch - 72ms/step\n",
            "Epoch 83/125\n",
            "\n",
            "Epoch 83: val_loss improved from 0.50349 to 0.49971, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.5253 - accuracy: 0.8296 - val_loss: 0.4997 - val_accuracy: 0.8460 - 26s/epoch - 73ms/step\n",
            "Epoch 84/125\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.49971\n",
            "351/351 - 25s - loss: 0.5205 - accuracy: 0.8324 - val_loss: 0.5169 - val_accuracy: 0.8418 - 25s/epoch - 72ms/step\n",
            "Epoch 85/125\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.49971\n",
            "351/351 - 25s - loss: 0.5228 - accuracy: 0.8299 - val_loss: 0.5165 - val_accuracy: 0.8374 - 25s/epoch - 71ms/step\n",
            "Epoch 86/125\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.49971\n",
            "351/351 - 26s - loss: 0.5169 - accuracy: 0.8343 - val_loss: 0.5149 - val_accuracy: 0.8458 - 26s/epoch - 73ms/step\n",
            "Epoch 87/125\n",
            "\n",
            "Epoch 87: val_loss improved from 0.49971 to 0.48899, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5174 - accuracy: 0.8298 - val_loss: 0.4890 - val_accuracy: 0.8482 - 25s/epoch - 72ms/step\n",
            "Epoch 88/125\n",
            "\n",
            "Epoch 88: val_loss improved from 0.48899 to 0.48216, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.5072 - accuracy: 0.8355 - val_loss: 0.4822 - val_accuracy: 0.8540 - 26s/epoch - 73ms/step\n",
            "Epoch 89/125\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.48216\n",
            "351/351 - 25s - loss: 0.5162 - accuracy: 0.8327 - val_loss: 0.4884 - val_accuracy: 0.8488 - 25s/epoch - 72ms/step\n",
            "Epoch 90/125\n",
            "\n",
            "Epoch 90: val_loss improved from 0.48216 to 0.46777, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5088 - accuracy: 0.8359 - val_loss: 0.4678 - val_accuracy: 0.8560 - 25s/epoch - 72ms/step\n",
            "Epoch 91/125\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.46777\n",
            "351/351 - 26s - loss: 0.5035 - accuracy: 0.8359 - val_loss: 0.5118 - val_accuracy: 0.8422 - 26s/epoch - 73ms/step\n",
            "Epoch 92/125\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.46777\n",
            "351/351 - 25s - loss: 0.5101 - accuracy: 0.8337 - val_loss: 0.4868 - val_accuracy: 0.8472 - 25s/epoch - 72ms/step\n",
            "Epoch 93/125\n",
            "\n",
            "Epoch 93: val_loss improved from 0.46777 to 0.46130, saving model to model.100epochs.hdf5\n",
            "351/351 - 25s - loss: 0.5039 - accuracy: 0.8359 - val_loss: 0.4613 - val_accuracy: 0.8596 - 25s/epoch - 72ms/step\n",
            "Epoch 94/125\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.46130\n",
            "351/351 - 26s - loss: 0.5031 - accuracy: 0.8376 - val_loss: 0.4983 - val_accuracy: 0.8504 - 26s/epoch - 73ms/step\n",
            "Epoch 95/125\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4998 - accuracy: 0.8381 - val_loss: 0.4874 - val_accuracy: 0.8498 - 25s/epoch - 72ms/step\n",
            "Epoch 96/125\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.46130\n",
            "351/351 - 26s - loss: 0.4961 - accuracy: 0.8398 - val_loss: 0.4990 - val_accuracy: 0.8468 - 26s/epoch - 73ms/step\n",
            "Epoch 97/125\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4958 - accuracy: 0.8388 - val_loss: 0.5148 - val_accuracy: 0.8410 - 25s/epoch - 72ms/step\n",
            "Epoch 98/125\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4905 - accuracy: 0.8415 - val_loss: 0.4782 - val_accuracy: 0.8534 - 25s/epoch - 72ms/step\n",
            "Epoch 99/125\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4886 - accuracy: 0.8413 - val_loss: 0.4629 - val_accuracy: 0.8560 - 25s/epoch - 72ms/step\n",
            "Epoch 100/125\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4850 - accuracy: 0.8438 - val_loss: 0.4832 - val_accuracy: 0.8502 - 25s/epoch - 72ms/step\n",
            "Epoch 101/125\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4863 - accuracy: 0.8439 - val_loss: 0.4985 - val_accuracy: 0.8506 - 25s/epoch - 72ms/step\n",
            "Epoch 102/125\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4843 - accuracy: 0.8428 - val_loss: 0.4962 - val_accuracy: 0.8474 - 25s/epoch - 72ms/step\n",
            "Epoch 103/125\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4823 - accuracy: 0.8443 - val_loss: 0.5024 - val_accuracy: 0.8468 - 25s/epoch - 70ms/step\n",
            "Epoch 104/125\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4844 - accuracy: 0.8419 - val_loss: 0.4702 - val_accuracy: 0.8526 - 25s/epoch - 72ms/step\n",
            "Epoch 105/125\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4761 - accuracy: 0.8458 - val_loss: 0.4680 - val_accuracy: 0.8576 - 25s/epoch - 71ms/step\n",
            "Epoch 106/125\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4766 - accuracy: 0.8457 - val_loss: 0.4889 - val_accuracy: 0.8466 - 25s/epoch - 72ms/step\n",
            "Epoch 107/125\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4734 - accuracy: 0.8468 - val_loss: 0.4753 - val_accuracy: 0.8534 - 25s/epoch - 72ms/step\n",
            "Epoch 108/125\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4689 - accuracy: 0.8478 - val_loss: 0.4700 - val_accuracy: 0.8552 - 25s/epoch - 72ms/step\n",
            "Epoch 109/125\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.46130\n",
            "351/351 - 26s - loss: 0.4694 - accuracy: 0.8477 - val_loss: 0.4761 - val_accuracy: 0.8530 - 26s/epoch - 73ms/step\n",
            "Epoch 110/125\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.46130\n",
            "351/351 - 25s - loss: 0.4698 - accuracy: 0.8480 - val_loss: 0.4785 - val_accuracy: 0.8500 - 25s/epoch - 72ms/step\n",
            "Epoch 111/125\n",
            "\n",
            "Epoch 111: val_loss improved from 0.46130 to 0.44848, saving model to model.100epochs.hdf5\n",
            "351/351 - 26s - loss: 0.4671 - accuracy: 0.8477 - val_loss: 0.4485 - val_accuracy: 0.8646 - 26s/epoch - 73ms/step\n",
            "Epoch 112/125\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4654 - accuracy: 0.8500 - val_loss: 0.4868 - val_accuracy: 0.8538 - 25s/epoch - 72ms/step\n",
            "Epoch 113/125\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4612 - accuracy: 0.8500 - val_loss: 0.4879 - val_accuracy: 0.8548 - 25s/epoch - 72ms/step\n",
            "Epoch 114/125\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4662 - accuracy: 0.8489 - val_loss: 0.4668 - val_accuracy: 0.8580 - 25s/epoch - 72ms/step\n",
            "Epoch 115/125\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4698 - accuracy: 0.8485 - val_loss: 0.4676 - val_accuracy: 0.8572 - 25s/epoch - 72ms/step\n",
            "Epoch 116/125\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4596 - accuracy: 0.8504 - val_loss: 0.4694 - val_accuracy: 0.8562 - 25s/epoch - 72ms/step\n",
            "Epoch 117/125\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.44848\n",
            "351/351 - 27s - loss: 0.4573 - accuracy: 0.8524 - val_loss: 0.4826 - val_accuracy: 0.8544 - 27s/epoch - 77ms/step\n",
            "Epoch 118/125\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4515 - accuracy: 0.8562 - val_loss: 0.4739 - val_accuracy: 0.8528 - 25s/epoch - 71ms/step\n",
            "Epoch 119/125\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.44848\n",
            "351/351 - 26s - loss: 0.4505 - accuracy: 0.8548 - val_loss: 0.4822 - val_accuracy: 0.8566 - 26s/epoch - 73ms/step\n",
            "Epoch 120/125\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4493 - accuracy: 0.8555 - val_loss: 0.4679 - val_accuracy: 0.8566 - 25s/epoch - 71ms/step\n",
            "Epoch 121/125\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4495 - accuracy: 0.8542 - val_loss: 0.4604 - val_accuracy: 0.8606 - 25s/epoch - 72ms/step\n",
            "Epoch 122/125\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.44848\n",
            "351/351 - 26s - loss: 0.4448 - accuracy: 0.8574 - val_loss: 0.4564 - val_accuracy: 0.8622 - 26s/epoch - 75ms/step\n",
            "Epoch 123/125\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.44848\n",
            "351/351 - 26s - loss: 0.4482 - accuracy: 0.8555 - val_loss: 0.4729 - val_accuracy: 0.8562 - 26s/epoch - 73ms/step\n",
            "Epoch 124/125\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.44848\n",
            "351/351 - 25s - loss: 0.4478 - accuracy: 0.8563 - val_loss: 0.4665 - val_accuracy: 0.8580 - 25s/epoch - 72ms/step\n",
            "Epoch 125/125\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.44848\n",
            "351/351 - 26s - loss: 0.4388 - accuracy: 0.8601 - val_loss: 0.4586 - val_accuracy: 0.8624 - 26s/epoch - 73ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 모델 평가하기"
      ],
      "metadata": {
        "id": "oEUDlyh_FdQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' %(scores[1]*100, scores[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niiYN2CcE2KG",
        "outputId": "c8aafe21-2128-44ae-e2f5-954c3a64f0d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 11ms/step - loss: 0.5033 - accuracy: 0.8489\n",
            "\n",
            "Test result: 84.890 loss: 0.503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선\n",
        "plt.plot(hist.history['accuracy'], label='train')\n",
        "plt.plot(hist.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "i5Ya79UHFtH4",
        "outputId": "1c81c7e3-d087-4f37-8a5e-f127a30e9ada"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}